<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="http://jekyllrb.com" version="3.4.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-05-10T14:37:25+08:00</updated><id>http://localhost:4000/</id><title type="html">code busy</title><subtitle>code busy的个人博客</subtitle><author><name>liushan</name></author><entry><title type="html">kubernetes浅入(一)</title><link href="http://localhost:4000/2018/05/09/kubernetes%E6%B5%85%E5%85%A5/" rel="alternate" type="text/html" title="kubernetes浅入(一)" /><published>2018-05-09T00:00:00+08:00</published><updated>2018-05-09T00:00:00+08:00</updated><id>http://localhost:4000/2018/05/09/kubernetes%E6%B5%85%E5%85%A5</id><content type="html" xml:base="http://localhost:4000/2018/05/09/kubernetes%E6%B5%85%E5%85%A5/">&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;公司需要搭建一个k8s集群用于爬虫快捷部署,临时看了mritd&lt;a href=&quot;https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/&quot;&gt;&lt;/a&gt;的搭建教程,基本算是可以使用了.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;本文仅做个人笔记使用,搭建过程参考自:&lt;a href=&quot;https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/&quot; target=&quot;_blank&quot;&gt;mritd的博文&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;为了快速搭建,本次搭建使用了mritd的脚本&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;系统和软件&quot;&gt;系统和软件&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;Ubuntu16.04 server&lt;/li&gt;
  &lt;li&gt;Kubernetes1.10.1&lt;/li&gt;
  &lt;li&gt;Docker 18.03.1-ce&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;软件和背景&quot;&gt;软件和背景&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;需要提前安装docker和docker-compose&lt;/li&gt;
  &lt;li&gt;etcd &lt;a href=&quot;https://yq.aliyun.com/articles/11035&quot;&gt;etcd简介参考文档&lt;/a&gt; ETCD是用于共享配置和服务发现的分布式，一致性的KV存储系统。&lt;/li&gt;
  &lt;li&gt;cfssl 用于生成ectd证书&lt;a href=&quot;https://github.com/cloudflare/cfssl/releases&quot;&gt;GitHub官网下载&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;hyperkube &lt;a href=&quot;https://github.com/kubernetes/kubernetes/blob/master/cluster/images/hyperkube/README.md&quot;&gt;官方介绍&lt;/a&gt;(用于安装kubelet)&lt;/li&gt;
  &lt;li&gt;本文使用4台机子搭建(ip地址根据自己需要修改)&lt;/li&gt;
&lt;/ol&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;IP&lt;/th&gt;
      &lt;th&gt;TYPE&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.1.30&lt;/td&gt;
      &lt;td&gt;master node etcd&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.1.31&lt;/td&gt;
      &lt;td&gt;node etcd&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.1.32&lt;/td&gt;
      &lt;td&gt;node etcd&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;192.168.1.33&lt;/td&gt;
      &lt;td&gt;node&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;开始搭建&quot;&gt;开始搭建&lt;/h1&gt;
&lt;p&gt;切换到root用户,在root家目录新建个文件夹用户存放后续需要用到的文件和配置,&lt;/p&gt;

&lt;p&gt;记得对从节点配置ssh免登陆&lt;/p&gt;

&lt;p&gt;我新建的目录为 k8s,后续安装不特别说明都基于 /root/k8s 此目录&lt;/p&gt;

&lt;p&gt;先查看安装目录结构&lt;br /&gt;
&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180509130102.png!700x999&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;一-安装cfssl&quot;&gt;一 安装cfssl&lt;/h2&gt;
&lt;p&gt;使用mritd的cnd下载二进制安装包,如果不能用,可到&lt;a href=&quot;https://github.com/cloudflare/cfssl/releases&quot;&gt;GitHub下载&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;11-安装&quot;&gt;1.1 安装&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget https://mritdftp.b0.upaiyun.com/cfssl/cfssl.tar.gz
tar -zxvf cfssl.tar.gz
mv cfssl cfssljson /usr/local/bin
chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson
rm -f cfssl.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;12-生成etcd证书&quot;&gt;1.2 生成etcd证书&lt;/h3&gt;
&lt;p&gt;mkdir ssl 
cd ssl&lt;/p&gt;
&lt;h4 id=&quot;etcd-csrjson&quot;&gt;etcd-csr.json&lt;/h4&gt;
&lt;p&gt;修改hosts相关配置为自己的ip&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;algo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rsa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;names&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;OU&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd Security&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;L&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Beijing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Beijing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hosts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;127.0.0.1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;localhost&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.61&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.62&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.63&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;etcd-gencertjson&quot;&gt;etcd-gencert.json&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;signing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;default&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;usages&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;signing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;key encipherment&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;server auth&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;client auth&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;expiry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;87600h&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;etcd-root-ca-csrjson&quot;&gt;etcd-root-ca-csr.json&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;algo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rsa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;names&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;OU&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd Security&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;L&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Beijing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Beijing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;etcd-root-ca&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;生成证书&quot;&gt;生成证书&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cfssl gencert --initca=true etcd-root-ca-csr.json | cfssljson --bare etcd-root-ca
cfssl gencert --ca etcd-root-ca.pem --ca-key etcd-root-ca-key.pem --config etcd-gencert.json etcd-csr.json | cfssljson --bare etcd
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;生成后结果如下&lt;br /&gt;
&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180509144247.png!700x999&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;二-安装etcd&quot;&gt;二 安装etcd&lt;/h2&gt;
&lt;p&gt;Etcd 这里采用最新的 3.2.18 版本，安装方式直接复制二进制文件、systemd service 配置
cd ~/k8s/
mkdir systemd &amp;amp;&amp;amp; cd systemd
touch etcd.service&lt;/p&gt;
&lt;h3 id=&quot;etcdservice&quot;&gt;etcd.service&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target

[Service]
Type=notify
WorkingDirectory=/var/lib/etcd/
EnvironmentFile=-/etc/etcd/etcd.conf
User=etcd
# set GOMAXPROCS to number of processors
ExecStart=/bin/bash -c &quot;GOMAXPROCS=$(nproc) /usr/local/bin/etcd --name=\&quot;${ETCD_NAME}\&quot; --data-dir=\&quot;${ETCD_DATA_DIR}\&quot; --listen-client-urls=\&quot;${ETCD_LISTEN_CLIENT_URLS}\&quot;&quot;
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;touch etcd.conf&lt;/p&gt;
&lt;h3 id=&quot;etcdconf&quot;&gt;etcd.conf&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# [member]
ETCD_NAME=etcd1
ETCD_DATA_DIR=&quot;/var/lib/etcd/etcd1.etcd&quot;
ETCD_WAL_DIR=&quot;/var/lib/etcd/wal&quot;
ETCD_SNAPSHOT_COUNT=&quot;100&quot;
ETCD_HEARTBEAT_INTERVAL=&quot;100&quot;
ETCD_ELECTION_TIMEOUT=&quot;1000&quot;
ETCD_LISTEN_PEER_URLS=&quot;https://192.168.1.61:2380&quot;
ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.1.61:2379,http://127.0.0.1:2379&quot;
ETCD_MAX_SNAPSHOTS=&quot;5&quot;
ETCD_MAX_WALS=&quot;5&quot;
#ETCD_CORS=&quot;&quot;

# [cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.1.61:2380&quot;
# if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &quot;test=http://...&quot;
ETCD_INITIAL_CLUSTER=&quot;etcd1=https://192.168.1.61:2380,etcd2=https://192.168.1.62:2380,etcd3=https://192.168.1.63:2380&quot;
ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;
ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;
ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.1.61:2379&quot;
#ETCD_DISCOVERY=&quot;&quot;
#ETCD_DISCOVERY_SRV=&quot;&quot;
#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;
#ETCD_DISCOVERY_PROXY=&quot;&quot;
#ETCD_STRICT_RECONFIG_CHECK=&quot;false&quot;
#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;

# [proxy]
#ETCD_PROXY=&quot;off&quot;
#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;
#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;
#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;
#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;
#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;

# [security]
ETCD_CERT_FILE=&quot;/etc/etcd/ssl/etcd.pem&quot;
ETCD_KEY_FILE=&quot;/etc/etcd/ssl/etcd-key.pem&quot;
ETCD_CLIENT_CERT_AUTH=&quot;true&quot;
ETCD_TRUSTED_CA_FILE=&quot;/etc/etcd/ssl/etcd-root-ca.pem&quot;
ETCD_AUTO_TLS=&quot;true&quot;
ETCD_PEER_CERT_FILE=&quot;/etc/etcd/ssl/etcd.pem&quot;
ETCD_PEER_KEY_FILE=&quot;/etc/etcd/ssl/etcd-key.pem&quot;
ETCD_PEER_CLIENT_CERT_AUTH=&quot;true&quot;
ETCD_PEER_TRUSTED_CA_FILE=&quot;/etc/etcd/ssl/etcd-root-ca.pem&quot;
ETCD_PEER_AUTO_TLS=&quot;true&quot;

# [logging]
#ETCD_DEBUG=&quot;false&quot;
# examples for -log-package-levels etcdserver=WARNING,security=DEBUG
#ETCD_LOG_PACKAGE_LEVELS=&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;touch install.sh&lt;/p&gt;
&lt;h3 id=&quot;install-sh&quot;&gt;install .sh&lt;/h3&gt;
&lt;p&gt;这里解释下,此处下载etcd安装包,为系统添加etcd用户,并赋值etcd用户权限,安装下载来的安装包,拷贝相关证书到/etc/etcd/目录中给etcd使用&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; -e

&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;3.2.18&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#下载etcd安装包&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;download&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; ! -f &lt;span class=&quot;s2&quot;&gt;&quot;etcd-v&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;-linux-amd64.tar.gz&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;wget https://github.com/coreos/etcd/releases/download/v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;-linux-amd64.tar.gz
        tar -zxvf etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;-linux-amd64.tar.gz
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 添加ectd相关用户和权限&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;preinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    getent group etcd &amp;gt;/dev/null &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; groupadd -r etcd
    getent passwd etcd &amp;gt;/dev/null &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; useradd -r -g etcd -d /var/lib/etcd -s /sbin/nologin -c &lt;span class=&quot;s2&quot;&gt;&quot;etcd user&quot;&lt;/span&gt; etcd
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;install&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -e &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy etcd...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    tar -zxvf etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;-linux-amd64.tar.gz
    cp etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;-linux-amd64/etcd&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; /usr/local/bin
    rm -rf etcd-v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCD_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;-linux-amd64

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -e &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy etcd config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp -r conf /etc/etcd
    chown -R etcd:etcd /etc/etcd
    chmod -R 755 /etc/etcd/ssl

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -e &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy etcd systemd config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp systemd/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.service /lib/systemd/system
    systemctl daemon-reload
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;postinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; ! -d &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/etcd&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /var/lib/etcd
        chown -R etcd:etcd /var/lib/etcd
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;


download
preinstall
install
postinstall
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;download : 从GitHub官网下载二进制文件并解压&lt;/li&gt;
  &lt;li&gt;preinstall : 创建etcd用户,并制定家目录登录shell,为Etcd做准备&lt;/li&gt;
  &lt;li&gt;install :  将下载来的二进制压缩包解压并复制到/usr/local/bin,后到conf中的文件复制到 /etc/etcd&lt;/li&gt;
  &lt;li&gt;postinstall : 安装后收尾工作，比如检测 /var/lib/etcd 是否存在，纠正权限等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;执行 ./install.sh,得到如下结果:&lt;br /&gt;
&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180510110948.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;font color=&quot;red&quot;&gt;注意:完后install后,将etcd目录scp到每台需要安装etcd的节点,修改etcd.conf 中的相关配置(ETCD_NAME,IP等),在每个etcd再执行install.sh &lt;/font&gt;

&lt;h2 id=&quot;三-安装kubernetes&quot;&gt;三 安装kubernetes&lt;/h2&gt;
&lt;p&gt;由于 kubelet 和 kube-proxy 用到的 kubeconfig 配置文件需要借助 kubectl 来生成，所以需要先安装一下 kubect&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget https://storage.googleapis.com/kubernetes-release/release/v1.10.1/bin/linux/amd64/hyperkube -O hyperkube_1.10.1
chmod +x hyperkube_1.10.1
cp hyperkube_1.10.1 /usr/local/bin/hyperkube
ln -s /usr/local/bin/hyperkube /usr/local/bin/kubectl
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;31生成k8s证书&quot;&gt;3.1生成k8s证书&lt;/h3&gt;
&lt;h4 id=&quot;admin-csrjson&quot;&gt;admin-csr.json&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;admin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hosts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;algo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rsa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;names&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BeiJing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;L&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BeiJing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;system:masters&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;OU&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;System&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;k8s-gencertjson&quot;&gt;k8s-gencert.json&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kubernetes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;algo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rsa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;names&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BeiJing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;L&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BeiJing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;k8s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;OU&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;System&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;kube-apiserver-csrjson&quot;&gt;kube-apiserver-csr.json&lt;/h4&gt;
&lt;p&gt;注意修改为自己的ip,10.254.0.1这个ip我暂时不听清楚具体是啥,貌似是k8s集群里类似路由地址的东西&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kubernetes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hosts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;127.0.0.1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;10.254.0.1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.30&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.31&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.32&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;192.168.1.33&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;*.kubernetes.master&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;localhost&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kubernetes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kubernetes.default&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kubernetes.default.svc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kubernetes.default.svc.cluster&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;kubernetes.default.svc.cluster.local&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;algo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rsa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;names&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BeiJing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;L&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BeiJing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;k8s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;OU&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;System&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;kube-proxy-csrjson&quot;&gt;kube-proxy-csr.json&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;system:kube-proxy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hosts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;algo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rsa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;names&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BeiJing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;L&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BeiJing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;k8s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;OU&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;System&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;生成证书操作&quot;&gt;生成证书操作:&lt;/h4&gt;
&lt;p&gt;可将此脚本写到一个 sh中,然后执行&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 生成 CA
cfssl gencert --initca=true k8s-root-ca-csr.json | cfssljson --bare k8s-root-ca

# 依次生成其他组件证书
for targetName in kube-apiserver admin kube-proxy; do
    cfssl gencert --ca k8s-root-ca.pem --ca-key k8s-root-ca-key.pem --config k8s-gencert.json --profile kubernetes $targetName-csr.json | cfssljson --bare $targetName
done

# 地址默认为 127.0.0.1:6443
# 如果在 master 上启用 kubelet 请在生成后的 kubeconfig 中
# 修改该地址为 当前MASTER_IP:6443
KUBE_APISERVER=&quot;https://127.0.0.1:6443&quot;
BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d ' ')
echo &quot;Tokne: ${BOOTSTRAP_TOKEN}&quot;

# 不要质疑 system:bootstrappers 用户组是否写错了，有疑问请参考官方文档
# https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/
cat &amp;gt; token.csv &amp;lt;&amp;lt;EOF
${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,&quot;system:bootstrappers&quot;
EOF

echo &quot;Create kubelet bootstrapping kubeconfig...&quot;
# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=bootstrap.kubeconfig
# 设置客户端认证参数
kubectl config set-credentials kubelet-bootstrap \
  --token=${BOOTSTRAP_TOKEN} \
  --kubeconfig=bootstrap.kubeconfig
# 设置上下文参数
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kubelet-bootstrap \
  --kubeconfig=bootstrap.kubeconfig
# 设置默认上下文
kubectl config use-context default --kubeconfig=bootstrap.kubeconfig

echo &quot;Create kube-proxy kubeconfig...&quot;
# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-proxy.kubeconfig
# 设置客户端认证参数
kubectl config set-credentials kube-proxy \
  --client-certificate=kube-proxy.pem \
  --client-key=kube-proxy-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-proxy.kubeconfig
# 设置上下文参数
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig
# 设置默认上下文
kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig

# 创建高级审计配置
cat &amp;gt;&amp;gt; audit-policy.yaml &amp;lt;&amp;lt;EOF
# Log all requests at the Metadata level.
apiVersion: audit.k8s.io/v1beta1
kind: Policy
rules:
- level: Metadata
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;生成完成后如下截图:&lt;br /&gt;
&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180510112658.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;32配置systemd&quot;&gt;3.2配置systemd&lt;/h3&gt;
&lt;p&gt;安装k8s都是用二进制文件的,所以需要手动创建systemd&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd k8s &amp;amp;&amp;amp; mkdir systemd  &amp;amp;&amp;amp; cd systemd
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;如果已经创建了这个目录就不需要了&lt;/p&gt;

&lt;h4 id=&quot;vim-kube-apiserverservice&quot;&gt;vim kube-apiserver.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
After=etcd.service

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/apiserver
User=kube
ExecStart=/usr/local/bin/hyperkube apiserver \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_ETCD_SERVERS \
            $KUBE_API_ADDRESS \
            $KUBE_API_PORT \
            $KUBELET_PORT \
            $KUBE_ALLOW_PRIV \
            $KUBE_SERVICE_ADDRESSES \
            $KUBE_ADMISSION_CONTROL \
            $KUBE_API_ARGS
Restart=on-failure
Type=notify
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;vim-kube-controller-managerservice&quot;&gt;vim kube-controller-manager.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/controller-manager
User=kube
ExecStart=/usr/local/bin/hyperkube controller-manager \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_MASTER \
            $KUBE_CONTROLLER_MANAGER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;vim-kubeletservice&quot;&gt;vim kubelet.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service

[Service]
WorkingDirectory=/var/lib/kubelet
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/kubelet
ExecStart=/usr/local/bin/hyperkube kubelet \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBELET_API_SERVER \
            $KUBELET_ADDRESS \
            $KUBELET_PORT \
            $KUBELET_HOSTNAME \
            $KUBE_ALLOW_PRIV \
            $KUBELET_ARGS
Restart=on-failure
KillMode=process

[Install]
WantedBy=multi-user.target

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;vim-kube-proxyservice&quot;&gt;vim kube-proxy.service&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/proxy
ExecStart=/usr/local/bin/hyperkube proxy \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_MASTER \
            $KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;vim-kube-schedulerservice&quot;&gt;vim kube-scheduler.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Kubernetes Scheduler Plugin
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/scheduler
User=kube
ExecStart=/usr/local/bin/hyperkube scheduler \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_MASTER \
            $KUBE_SCHEDULER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;至此 systemd创建完成,后续通过脚本会将此此目录中是的文件 copy到系统的systemd目录中的&lt;br /&gt;
返回上层目录,回到k8s目录,继续创建相关配置&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# cd .. &amp;amp;&amp;amp; pwd
/root/k8s
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;33k8s-配置master节点&quot;&gt;3.3k8s-配置master节点&lt;/h3&gt;
&lt;p&gt;/root/k8s目录下进行&lt;br /&gt;
Master 节点主要会运行 3 各组件: kube-apiserver、kube-controller-manager、kube-scheduler，其中用到的配置文件如下&lt;/p&gt;

&lt;h4 id=&quot;config&quot;&gt;config&lt;/h4&gt;
&lt;p&gt;config 是一个通用配置文件，值得注意的是由于安装时对于 Node、Master 节点都会包含该文件，在 Node 节点上请注释掉 KUBE_MASTER 变量，因为 Node 节点需要做 HA，要连接本地的 6443 加密端口；而这个变量将会覆盖 kubeconfig 中指定的 127.0.0.1:6443 地址&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes system config
#
# The following values are used to configure various aspects of all
# kubernetes services, including
#
#   kube-apiserver.service
#   kube-controller-manager.service
#   kube-scheduler.service
#   kubelet.service
#   kube-proxy.service
# logging to stderr means we get it in the systemd journal
KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;

# journal message level, 0 is debug
KUBE_LOG_LEVEL=&quot;--v=2&quot;

# Should this cluster be allowed to run privileged docker containers
KUBE_ALLOW_PRIV=&quot;--allow-privileged=true&quot;

# How the controller-manager, scheduler, and proxy find the apiserver
KUBE_MASTER=&quot;--master=http://127.0.0.1:8080&quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;apiserver&quot;&gt;apiserver&lt;/h4&gt;
&lt;p&gt;apiserver 配置相对于 1.8 略有变动，其中准入控制器(admission control)选项名称变为了 –enable-admission-plugins，控制器列表也有相应变化，这里采用官方推荐配置，具体请参考 &lt;a href=&quot;https://kubernetes.io/docs/admin/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use&quot;&gt;官方文档&lt;/a&gt;&lt;br /&gt;
注意,此处直接复制了mritd的文档.其中ip需要改为自己的&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes system config
#
# The following values are used to configure the kube-apiserver
#

# The address on the local server to listen to.
KUBE_API_ADDRESS=&quot;--advertise-address=192.168.1.61 --bind-address=192.168.1.61&quot;

# The port on the local server to listen on.
KUBE_API_PORT=&quot;--secure-port=6443&quot;

# Port minions listen on
# KUBELET_PORT=&quot;--kubelet-port=10250&quot;

# Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS=&quot;--etcd-servers=https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379&quot;

# Address range to use for services
KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;

# default admission control policies
KUBE_ADMISSION_CONTROL=&quot;--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction&quot;

# Add your own!
KUBE_API_ARGS=&quot; --anonymous-auth=false \
                --apiserver-count=3 \
                --audit-log-maxage=30 \
                --audit-log-maxbackup=3 \
                --audit-log-maxsize=100 \
                --audit-log-path=/var/log/kube-audit/audit.log \
                --audit-policy-file=/etc/kubernetes/audit-policy.yaml \
                --authorization-mode=Node,RBAC \
                --client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                --enable-bootstrap-token-auth \
                --enable-garbage-collector \
                --enable-logs-handler \
                --enable-swagger-ui \
                --etcd-cafile=/etc/etcd/ssl/etcd-root-ca.pem \
                --etcd-certfile=/etc/etcd/ssl/etcd.pem \
                --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem \
                --etcd-compaction-interval=5m0s \
                --etcd-count-metric-poll-period=1m0s \
                --event-ttl=48h0m0s \
                --kubelet-https=true \
                --kubelet-timeout=3s \
                --log-flush-frequency=5s \
                --token-auth-file=/etc/kubernetes/token.csv \
                --tls-cert-file=/etc/kubernetes/ssl/kube-apiserver.pem \
                --tls-private-key-file=/etc/kubernetes/ssl/kube-apiserver-key.pem \
                --service-node-port-range=30000-50000 \
                --service-account-key-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                --storage-backend=etcd3 \
                --enable-swagger-ui=true&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;controller-manager&quot;&gt;controller-manager&lt;/h4&gt;
&lt;p&gt;controller manager 配置默认开启了证书轮换能力用于自动签署 kueblet 证书，并且证书时间也设置了 10 年，可自行调整；增加了 –controllers 选项以指定开启全部控制器&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# The following values are used to configure the kubernetes controller-manager

# defaults from config and apiserver should be adequate

# Add your own!
KUBE_CONTROLLER_MANAGER_ARGS=&quot;  --bind-address=0.0.0.0 \
                                --cluster-name=kubernetes \
                                --cluster-signing-cert-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                                --cluster-signing-key-file=/etc/kubernetes/ssl/k8s-root-ca-key.pem \
                                --controllers=*,bootstrapsigner,tokencleaner \
                                --deployment-controller-sync-period=10s \
                                --experimental-cluster-signing-duration=86700h0m0s \
                                --leader-elect=true \
                                --node-monitor-grace-period=40s \
                                --node-monitor-period=5s \
                                --pod-eviction-timeout=5m0s \
                                --terminated-pod-gc-threshold=50 \
                                --root-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \
                                --service-account-private-key-file=/etc/kubernetes/ssl/k8s-root-ca-key.pem \
                                --feature-gates=RotateKubeletServerCertificate=true&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;scheduler&quot;&gt;scheduler&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes scheduler config

# default config should be adequate

# Add your own!
KUBE_SCHEDULER_ARGS=&quot;   --address=0.0.0.0 \
                        --leader-elect=true \
                        --algorithm-provider=DefaultProvider&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;34k8s-配置node节点&quot;&gt;3.4k8s-配置node节点&lt;/h3&gt;
&lt;p&gt;Node 节点上主要有 kubelet、kube-proxy 组件，用到的配置如下&lt;/p&gt;

&lt;h4 id=&quot;kubelet&quot;&gt;kubelet&lt;/h4&gt;
&lt;p&gt;kubeket 默认也开启了证书轮换能力以保证自动续签相关证书，同时增加了 –node-labels 选项为 node 打一个标签，关于这个标签最后部分会有讨论，如果在 master 上启动 kubelet，请将 node-role.kubernetes.io/k8s-node=true 修改为 node-role.kubernetes.io/k8s-master=true&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes kubelet (minion) config

# The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces)
KUBELET_ADDRESS=&quot;--node-ip=192.168.1.61&quot;

# The port for the info server to serve on
# KUBELET_PORT=&quot;--port=10250&quot;

# You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&quot;--hostname-override=k1.node&quot;

# location of the api-server
# KUBELET_API_SERVER=&quot;&quot;

# Add your own!
KUBELET_ARGS=&quot;  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \
                --cert-dir=/etc/kubernetes/ssl \
                --cgroup-driver=cgroupfs \
                --cluster-dns=10.254.0.2 \
                --cluster-domain=cluster.local. \
                --fail-swap-on=false \
                --feature-gates=RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true \
                --node-labels=node-role.kubernetes.io/k8s-node=true \
                --image-gc-high-threshold=70 \
                --image-gc-low-threshold=50 \
                --kube-reserved=cpu=500m,memory=512Mi,ephemeral-storage=1Gi \
                --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \
                --system-reserved=cpu=1000m,memory=1024Mi,ephemeral-storage=1Gi \
                --serialize-image-pulls=false \
                --sync-frequency=30s \
                --pod-infra-container-image=k8s.gcr.io/pause-amd64:3.0 \
                --resolv-conf=/etc/resolv.conf \
                --rotate-certificates&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;proxy&quot;&gt;proxy&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes proxy config
# default config should be adequate
# Add your own!
KUBE_PROXY_ARGS=&quot;--bind-address=0.0.0.0 \
                 --hostname-override=k1.node \
                 --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \
                 --cluster-cidr=10.254.0.0/16&quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;安装集群组件&quot;&gt;安装集群组件&lt;/h4&gt;
&lt;p&gt;完成上述后,会得到如下一个目录结构(需要保证这个目录结构,才能使用接下来的安装脚本)&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;k8s
├── conf
│   ├── apiserver
│   ├── audit-policy.yaml
│   ├── bootstrap.kubeconfig
│   ├── config
│   ├── controller-manager
│   ├── kubelet
│   ├── kube-proxy.kubeconfig
│   ├── proxy
│   ├── scheduler
│   ├── ssl
│   │   ├── admin.csr
│   │   ├── admin-csr.json
│   │   ├── admin-key.pem
│   │   ├── admin.pem
│   │   ├── k8s-gencert.json
│   │   ├── k8s-root-ca.csr
│   │   ├── k8s-root-ca-csr.json
│   │   ├── k8s-root-ca-key.pem
│   │   ├── k8s-root-ca.pem
│   │   ├── kube-apiserver.csr
│   │   ├── kube-apiserver-csr.json
│   │   ├── kube-apiserver-key.pem
│   │   ├── kube-apiserver.pem
│   │   ├── kube-proxy.csr
│   │   ├── kube-proxy-csr.json
│   │   ├── kube-proxy-key.pem
│   │   └── kube-proxy.pem
│   └── token.csv
├── hyperkube_1.10.1
├── install.sh
└── systemd
    ├── kube-apiserver.service
    ├── kube-controller-manager.service
    ├── kubelet.service
    ├── kube-proxy.service
    └── kube-scheduler.service

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;installsh&quot;&gt;install.sh&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; -e

&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1.10.1&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;download_k8s&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; ! -f &lt;span class=&quot;s2&quot;&gt;&quot;hyperkube_&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;wget https://storage.googleapis.com/kubernetes-release/release/v&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin/linux/amd64/hyperkube -O hyperkube_&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
        chmod +x hyperkube_&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;preinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    getent group kube &amp;gt;/dev/null &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; groupadd -r kube
    getent passwd kube &amp;gt;/dev/null &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; useradd -r -g kube -d / -s /sbin/nologin -c &lt;span class=&quot;s2&quot;&gt;&quot;Kubernetes user&quot;&lt;/span&gt; kube
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;install_k8s&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -e &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy hyperkube...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp hyperkube_&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBE_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; /usr/local/bin/hyperkube

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -e &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Create symbolic link...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    ln -sf /usr/local/bin/hyperkube /usr/local/bin/kubectl

    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -e &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy kubernetes config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp -r conf /etc/kubernetes
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; -d &lt;span class=&quot;s2&quot;&gt;&quot;/etc/kubernetes/ssl&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;chown -R kube:kube /etc/kubernetes/ssl
    &lt;span class=&quot;k&quot;&gt;fi

    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -e &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[32mINFO: Copy kubernetes systemd config...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;33[0m&quot;&lt;/span&gt;
    cp systemd/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.service /lib/systemd/system
    systemctl daemon-reload
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;postinstall&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; ! -d &lt;span class=&quot;s2&quot;&gt;&quot;/var/log/kube-audit&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /var/log/kube-audit
    &lt;span class=&quot;k&quot;&gt;fi

    if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; ! -d &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/kubelet&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /var/lib/kubelet
    &lt;span class=&quot;k&quot;&gt;fi

    if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; ! -d &lt;span class=&quot;s2&quot;&gt;&quot;/usr/libexec&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;; &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;mkdir /usr/libexec
    &lt;span class=&quot;k&quot;&gt;fi
    &lt;/span&gt;chown -R kube:kube /var/log/kube-audit /var/lib/kubelet /usr/libexec
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;


download_k8s
preinstall
install_k8s
postinstall
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;脚本解释如下:
    &lt;blockquote&gt;
      &lt;p&gt;download_k8s: 下载 hyperkube 二进制文件
preinstall: 安装前处理，同 etcd 一样创建 kube 普通用户指定家目录、shell 等
install_k8s: 复制 hyperkube 到安装目录，为 kubectl 创建软连接(为啥创建软连接就能执行请自行阅读 源码)，复制相关配置到对应目录，并处理权限
postinstall: 收尾工作，创建日志目录等，并处理权限&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;font color=&quot;red&quot;&gt; &lt;h5&gt;最后执行此脚本安装即可，将k8s目录scp到每个节点 执行install.sh 此外，应确保每个节点安装了 ipset、conntrack 两个包，因为 kube-proxy 组件会使用其处理 iptables 规则等&lt;/h5&gt;&lt;/font&gt;

&lt;h2 id=&quot;四-启动集群&quot;&gt;四 启动集群&lt;/h2&gt;

&lt;h3 id=&quot;41-启动master&quot;&gt;4.1 启动master&lt;/h3&gt;
&lt;p&gt;对于 master 节点启动无需做过多处理，多个 master 只要保证 apiserver 等配置中的 ip 地址监听没问题后直接启动即可&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl daemon-reload
systemctl start kube-apiserver
systemctl start kube-controller-manager
systemctl start kube-scheduler
systemctl enable kube-apiserver
systemctl enable kube-controller-manager
systemctl enable kube-scheduler
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;42-启动node&quot;&gt;4.2 启动node&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl daemon-reload
systemctl start kubelet
systemctl start kube-proxy
systemctl enable kubelet
systemctl enable kube-proxy
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;其中,如果master也需要跑任务的话, kubelet 和 kube-proxy 也需要在master节点启动&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;启动完后如图&lt;br /&gt;
&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180510114912.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;五-配置集群网络相关&quot;&gt;五 配置集群网络相关&lt;/h2&gt;
&lt;p&gt;由于 HA 等功能需要，对于 Node 需要做一些处理才能启动，主要有以下两个地方需要处理&lt;/p&gt;
&lt;h3 id=&quot;51-nginx-proxy&quot;&gt;5.1 nginx-proxy&lt;/h3&gt;
&lt;p&gt;在启动 kubelet、kube-proxy 服务之前，需要在本地启动 nginx 来 tcp 负载均衡 apiserver 6443 端口，nginx-proxy 使用 docker + systemd 启动，配置如下&lt;br /&gt;
注意: 对于在 master 节点启动 kubelet 来说，不需要 nginx 做负载均衡；可以跳过此步骤，并修改 kubelet.kubeconfig、kube-proxy.kubeconfig 中的 apiserver 地址为当前 master ip 6443 端口即可&lt;/p&gt;
&lt;h4 id=&quot;nginx-proxyservice&quot;&gt;nginx-proxy.service&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=kubernetes apiserver docker wrapper
Wants=docker.socket
After=docker.service

[Service]
User=root
PermissionsStartOnly=true
ExecStart=/usr/bin/docker run -p 127.0.0.1:6443:6443 \
                              -v /etc/nginx:/etc/nginx \
                              --name nginx-proxy \
                              --net=host \
                              --restart=on-failure:5 \
                              --memory=512M \
                              nginx:1.13.12-alpine
ExecStartPre=-/usr/bin/docker rm -f nginx-proxy
ExecStop=/usr/bin/docker stop nginx-proxy
Restart=always
RestartSec=15s
TimeoutStartSec=30s

[Install]
WantedBy=multi-user.target

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;nginxconf&quot;&gt;nginx.conf&lt;/h4&gt;
&lt;p&gt;注意修改ip&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;error_log stderr notice;

worker_processes auto;
events {
        multi_accept on;
        use epoll;
        worker_connections 1024;
}

stream {
    upstream kube_apiserver {
        least_conn;
        server 192.168.1.30:6443;
        server 192.168.1.31:6443;
        server 192.168.1.32:6443;
    }

    server {
        listen        0.0.0.0:6443;
        proxy_pass    kube_apiserver;
        proxy_timeout 10m;
        proxy_connect_timeout 1s;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;启动-apiserver-的本地负载均衡&quot;&gt;启动 apiserver 的本地负载均衡&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir /etc/nginx
cp nginx.conf /etc/nginx
cp nginx-proxy.service /lib/systemd/system

systemctl daemon-reload
systemctl start nginx-proxy
systemctl enable nginx-proxy
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;tls-bootstrapping&quot;&gt;TLS bootstrapping&lt;/h4&gt;
&lt;p&gt;创建好 nginx-proxy 后不要忘记为 TLS Bootstrap 创建相应的 RBAC 规则，这些规则能实现证自动签署 TLS Bootstrap 发出的 CSR 请求，从而实现证书轮换(创建一次即可)；详情请参考 &lt;a href=&quot;https://mritd.me/2018/01/07/kubernetes-tls-bootstrapping-note/&quot;&gt;Kubernetes TLS bootstrapping 那点事&lt;/a&gt;&lt;/p&gt;

&lt;h5 id=&quot;tls-bootstrapping-clusterroleyaml&quot;&gt;tls-bootstrapping-clusterrole.yaml&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# A ClusterRole which instructs the CSR approver to approve a node requesting a
# serving cert matching its client cert.
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver
rules:
- apiGroups: [&quot;certificates.k8s.io&quot;]
  resources: [&quot;certificatesigningrequests/selfnodeserver&quot;]
  verbs: [&quot;create&quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上述yaml需要再master节点执行创建&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 给与 kubelet-bootstrap 用户进行 node-bootstrapper 的权限
kubectl create clusterrolebinding kubelet-bootstrap \
    --clusterrole=system:node-bootstrapper \
    --user=kubelet-bootstrap

kubectl create -f tls-bootstrapping-clusterrole.yaml

# 自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求
kubectl create clusterrolebinding node-client-auto-approve-csr \
        --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient \
        --group=system:bootstrappers

# 自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求
kubectl create clusterrolebinding node-client-auto-renew-crt \
        --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient \
        --group=system:nodes

# 自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求
kubectl create clusterrolebinding node-server-auto-renew-crt \
        --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver \
        --group=system:nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;执行启动&quot;&gt;执行启动&lt;/h4&gt;
&lt;p&gt;多节点部署时先启动好 nginx-proxy，然后修改好相应配置的 ip 地址等配置，最终直接启动即可(master 上启动 kubelet 不要忘了修改 kubeconfig 中的 apiserver 地址，还有对应的 kubelet 的 node label)&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl daemon-reload
systemctl restart kubelet
systemctl restart kube-proxy
systemctl enable kubelet
systemctl enable kube-proxy

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;启动成功后得到如下图&lt;br /&gt;
&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180510115842.png!700x999&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;
截图来自mritd,由于是公司机器,不能直接暴露,后续个人搭建时,再来替换为自己的&lt;/p&gt;

&lt;h3 id=&quot;52-calico&quot;&gt;5.2 Calico&lt;/h3&gt;
&lt;p&gt;Calico 安装仍然延续以前的方案，使用 Daemonset 安装 cni 组件，使用 systemd 控制 calico-node 以确保 calico-node 能正确的拿到主机名等&lt;/p&gt;
&lt;h4 id=&quot;修改calico配置&quot;&gt;修改calico配置&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/calico.yaml -O calico.example.yaml

ETCD_CERT=`cat /etc/etcd/ssl/etcd.pem | base64 | tr -d '\n'`
ETCD_KEY=`cat /etc/etcd/ssl/etcd-key.pem | base64 | tr -d '\n'`
ETCD_CA=`cat /etc/etcd/ssl/etcd-root-ca.pem | base64 | tr -d '\n'`
ETCD_ENDPOINTS=&quot;https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379&quot;

cp calico.example.yaml calico.yaml

sed -i &quot;s@.*etcd_endpoints:.*@\ \ etcd_endpoints:\ \&quot;${ETCD_ENDPOINTS}\&quot;@gi&quot; calico.yaml

sed -i &quot;s@.*etcd-cert:.*@\ \ etcd-cert:\ ${ETCD_CERT}@gi&quot; calico.yaml
sed -i &quot;s@.*etcd-key:.*@\ \ etcd-key:\ ${ETCD_KEY}@gi&quot; calico.yaml
sed -i &quot;s@.*etcd-ca:.*@\ \ etcd-ca:\ ${ETCD_CA}@gi&quot; calico.yaml

sed -i 's@.*etcd_ca:.*@\ \ etcd_ca:\ &quot;/calico-secrets/etcd-ca&quot;@gi' calico.yaml
sed -i 's@.*etcd_cert:.*@\ \ etcd_cert:\ &quot;/calico-secrets/etcd-cert&quot;@gi' calico.yaml
sed -i 's@.*etcd_key:.*@\ \ etcd_key:\ &quot;/calico-secrets/etcd-key&quot;@gi' calico.yaml

# 注释掉 calico-node 部分(由 Systemd 接管)
sed -i '123,219s@.*@#&amp;amp;@gi' calico.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;创建systemd&quot;&gt;创建systemd&lt;/h4&gt;
&lt;h5&gt;注意: 创建 systemd service 配置文件要在每个节点上都执行&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;K8S_MASTER_IP=&quot;192.168.1.61&quot;
HOSTNAME=`cat /etc/hostname`
ETCD_ENDPOINTS=&quot;https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379&quot;

cat &amp;gt; /lib/systemd/system/calico-node.service &amp;lt;&amp;lt;EOF
[Unit]
Description=calico node
After=docker.service
Requires=docker.service

[Service]
User=root
Environment=ETCD_ENDPOINTS=${ETCD_ENDPOINTS}
PermissionsStartOnly=true
ExecStart=/usr/bin/docker run   --net=host --privileged --name=calico-node \\
                                -e ETCD_ENDPOINTS=\${ETCD_ENDPOINTS} \\
                                -e ETCD_CA_CERT_FILE=/etc/etcd/ssl/etcd-root-ca.pem \\
                                -e ETCD_CERT_FILE=/etc/etcd/ssl/etcd.pem \\
                                -e ETCD_KEY_FILE=/etc/etcd/ssl/etcd-key.pem \\
                                -e NODENAME=${HOSTNAME} \\
                                -e IP= \\
                                -e IP_AUTODETECTION_METHOD=can-reach=${K8S_MASTER_IP} \\
                                -e AS=64512 \\
                                -e CLUSTER_TYPE=k8s,bgp \\
                                -e CALICO_IPV4POOL_CIDR=10.20.0.0/16 \\
                                -e CALICO_IPV4POOL_IPIP=always \\
                                -e CALICO_LIBNETWORK_ENABLED=true \\
                                -e CALICO_NETWORKING_BACKEND=bird \\
                                -e CALICO_DISABLE_FILE_LOGGING=true \\
                                -e FELIX_IPV6SUPPORT=false \\
                                -e FELIX_DEFAULTENDPOINTTOHOSTACTION=ACCEPT \\
                                -e FELIX_LOGSEVERITYSCREEN=info \\
                                -e FELIX_IPINIPMTU=1440 \\
                                -e FELIX_HEALTHENABLED=true \\
                                -e CALICO_K8S_NODE_REF=${HOSTNAME} \\
                                -v /etc/calico/etcd-root-ca.pem:/etc/etcd/ssl/etcd-root-ca.pem \\
                                -v /etc/calico/etcd.pem:/etc/etcd/ssl/etcd.pem \\
                                -v /etc/calico/etcd-key.pem:/etc/etcd/ssl/etcd-key.pem \\
                                -v /lib/modules:/lib/modules \\
                                -v /var/lib/calico:/var/lib/calico \\
                                -v /var/run/calico:/var/run/calico \\
                                quay.io/calico/node:v3.1.0
ExecStop=/usr/bin/docker rm -f calico-node
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;font color=&quot;red&quot;&gt; 对于以上脚本中的 K8S_MASTER_IP 变量，只需要填写一个 master ip 即可，这个变量用于 calico 自动选择 IP 使用；在宿主机有多张网卡的情况下，calcio node 会自动获取一个 IP，获取原则就是尝试是否能够联通这个 master ip 由于 calico 需要使用 etcd 存储数据，所以需要复制 etcd 证书到相关目录，/etc/calico 需要在每个节点都有&lt;/font&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cp -r /etc/etcd/ssl /etc/calico
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;修改kubelet配置&quot;&gt;修改kubelet配置&lt;/h4&gt;
&lt;p&gt;使用 Calico 后需要修改 kubelet 配置增加 CNI 设置(–network-plugin=cni)，修改后配置如下 &lt;br /&gt;
增加了 –network-plugin=cni \    这个配置&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###
# kubernetes kubelet (minion) config

# The address for the info server to serve on (set to 0.0.0.0 or &quot;&quot; for all interfaces)
KUBELET_ADDRESS=&quot;--node-ip=192.168.1.30&quot;

# The port for the info server to serve on
# KUBELET_PORT=&quot;--port=10250&quot;

# You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&quot;--hostname-override=k1.node&quot;

# location of the api-server
# KUBELET_API_SERVER=&quot;&quot;

# Add your own!
KUBELET_ARGS=&quot;  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \
                --cert-dir=/etc/kubernetes/ssl \
                --cgroup-driver=cgroupfs \
                --network-plugin=cni \
                --cluster-dns=10.254.0.2 \
                --cluster-domain=cluster.local. \
                --fail-swap-on=false \
                --feature-gates=RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true \
                --node-labels=node-role.kubernetes.io/k8s-master=true \
                --image-gc-high-threshold=70 \
                --image-gc-low-threshold=50 \
                --kube-reserved=cpu=500m,memory=512Mi,ephemeral-storage=1Gi \
                --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \
                --system-reserved=cpu=1000m,memory=1024Mi,ephemeral-storage=1Gi \
                --serialize-image-pulls=false \
                --sync-frequency=30s \
                --pod-infra-container-image=k8s.gcr.io/pause-amd64:3.0 \
                --resolv-conf=/etc/resolv.conf \
                --rotate-certificates&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;创建-calico-daemonset&quot;&gt;创建 Calico Daemonset&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 先创建 RBAC
kubectl apply -f \
https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/rbac.yaml

# 再创建 Calico Daemonset
kubectl create -f calico.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;启动-calico-node&quot;&gt;启动 Calico Node&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl daemon-reload
systemctl restart calico-node
systemctl enable calico-node

# 等待 20s 拉取镜像
sleep 20
systemctl restart kubelet
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;测试网络&quot;&gt;测试网络&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 创建 deployment
cat &amp;lt;&amp;lt; EOF &amp;gt;&amp;gt; demo.deploy.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-deployment
spec:
  replicas: 5
  selector:
    matchLabels:
      app: demo
  template:
    metadata:
      labels:
        app: demo
    spec:
      containers:
      - name: demo
        image: mritd/demo
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
EOF
kubectl create -f demo.deploy.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;截图引用自mritd&lt;br /&gt;
&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180510120356.png!700x999&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;53-coredns&quot;&gt;5.3 coreDNS&lt;/h3&gt;
&lt;p&gt;此处使用的mritd的脚本自动安装的&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd ~ 
git clone https://github.com/mritd/ktool
cd /root/ktool/k8s/addons/coredns

# 执行上面的替换脚本
./deploy.sh

# 创建 CoreDNS
kubectl create -f coredns.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;替换脚本内容为:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Deploys CoreDNS to a cluster currently running Kube-DNS.&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;SERVICE_CIDR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:-&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.254.0.0/16&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;POD_CIDR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:-&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.20.0.0/16&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;CLUSTER_DNS_IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:-&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.254.0.2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;CLUSTER_DOMAIN&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:-&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.local&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;YAML_TEMPLATE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:-&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/coredns.yaml.sed&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;

sed -e s/CLUSTER_DNS_IP/&lt;span class=&quot;nv&quot;&gt;$CLUSTER_DNS_IP&lt;/span&gt;/g -e s/CLUSTER_DOMAIN/&lt;span class=&quot;nv&quot;&gt;$CLUSTER_DOMAIN&lt;/span&gt;/g -e s?SERVICE_CIDR?&lt;span class=&quot;nv&quot;&gt;$SERVICE_CIDR&lt;/span&gt;?g -e s?POD_CIDR?&lt;span class=&quot;nv&quot;&gt;$POD_CIDR&lt;/span&gt;?g &lt;span class=&quot;nv&quot;&gt;$YAML_TEMPLATE&lt;/span&gt; &amp;gt; coredns.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;部署dns自动扩容&quot;&gt;部署DNS自动扩容&lt;/h4&gt;
&lt;p&gt;vim dns-horizontal-autoscaler.yaml&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Copyright 2016 The Kubernetes Authors.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

kind: ServiceAccount
apiVersion: v1
metadata:
  name: kube-dns-autoscaler
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:kube-dns-autoscaler
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
rules:
  - apiGroups: [&quot;&quot;]
    resources: [&quot;nodes&quot;]
    verbs: [&quot;list&quot;]
  - apiGroups: [&quot;&quot;]
    resources: [&quot;replicationcontrollers/scale&quot;]
    verbs: [&quot;get&quot;, &quot;update&quot;]
  - apiGroups: [&quot;extensions&quot;]
    resources: [&quot;deployments/scale&quot;, &quot;replicasets/scale&quot;]
    verbs: [&quot;get&quot;, &quot;update&quot;]
# Remove the configmaps rule once below issue is fixed:
# kubernetes-incubator/cluster-proportional-autoscaler#16
  - apiGroups: [&quot;&quot;]
    resources: [&quot;configmaps&quot;]
    verbs: [&quot;get&quot;, &quot;create&quot;]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:kube-dns-autoscaler
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
  - kind: ServiceAccount
    name: kube-dns-autoscaler
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: system:kube-dns-autoscaler
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kube-dns-autoscaler
  namespace: kube-system
  labels:
    k8s-app: kube-dns-autoscaler
    kubernetes.io/cluster-service: &quot;true&quot;
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  selector:
    matchLabels:
      k8s-app: kube-dns-autoscaler
  template:
    metadata:
      labels:
        k8s-app: kube-dns-autoscaler
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      priorityClassName: system-cluster-critical
      containers:
      - name: autoscaler
        image: k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.1.2-r2
        resources:
            requests:
                cpu: &quot;20m&quot;
                memory: &quot;10Mi&quot;
        command:
          - /cluster-proportional-autoscaler
          - --namespace=kube-system
          - --configmap=kube-dns-autoscaler
          # Should keep target in sync with cluster/addons/dns/kube-dns.yaml.base
          - --target=Deployment/kube-dns
          # When cluster is using large nodes(with more cores), &quot;coresPerReplica&quot; should dominate.
          # If using small nodes, &quot;nodesPerReplica&quot; should dominate.
          - --default-params={&quot;linear&quot;:{&quot;coresPerReplica&quot;:256,&quot;nodesPerReplica&quot;:16,&quot;preventSinglePointFailure&quot;:true}}
          - --logtostderr=true
          - --v=2
      tolerations:
      - key: &quot;CriticalAddonsOnly&quot;
        operator: &quot;Exists&quot;
      serviceAccountName: kube-dns-autoscaler
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;执行yaml创建即可完成DNS的自动扩容&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create -f dns-horizontal-autoscaler.yaml 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;六-k8s-监控heapster&quot;&gt;六 k8s-监控heapster&lt;/h2&gt;
&lt;p&gt;直接yaml创建即可&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/grafana.yaml
kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/heapster.yaml
kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/influxdb.yaml
kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;至此,搭建完成 ,集群已可以正常使用.如需要管理页面的可翻看下面的内容,不需要就不用了&lt;/p&gt;
&lt;h2 id=&quot;七-k8s-图形管理页面-dashboard&quot;&gt;七 k8s-图形管理页面 Dashboard&lt;/h2&gt;
&lt;p&gt;因为本次搭建没有部署Dashboard,具体搭建可看mritd的 &lt;a href=&quot;https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/#%E5%85%AB%E9%83%A8%E7%BD%B2-dashboard&quot;&gt;部署 Dashboard&lt;/a&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;本文参考来自mritd的&lt;a href=&quot;https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube&quot;&gt;Kubernetes 1.10.1 集群搭建&lt;/a&gt; ,其中大量脚本使用mritd提供&lt;/strong&gt;&lt;/p&gt;</content><author><name>liushan</name></author><summary type="html"></summary></entry><entry><title type="html">flume的搭建和简单使用</title><link href="http://localhost:4000/2018/05/02/flume%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8/" rel="alternate" type="text/html" title="flume的搭建和简单使用" /><published>2018-05-02T00:00:00+08:00</published><updated>2018-05-02T00:00:00+08:00</updated><id>http://localhost:4000/2018/05/02/flume%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8</id><content type="html" xml:base="http://localhost:4000/2018/05/02/flume%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8/">&lt;h3 id=&quot;flume-简介&quot;&gt;flume 简介:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;百度百科:&lt;br /&gt;
  Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。
  当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。&lt;/li&gt;
  &lt;li&gt;简介2&lt;br /&gt;
  1) Flume 提供一个分布式的，可靠的，对大数据量的日志进行高效收集、聚集、移动的服务， Flume 只能在 Unix 环境下运行。&lt;br /&gt;
  2) Flume 基于流式架构，容错性强，也很灵活简单。&lt;br /&gt;
  3) Flume、Kafka 用来实时进行数据收集，Spark、Storm 用来实时处理数据，impala 用来实 时查询。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;模式&quot;&gt;模式&lt;/h3&gt;
&lt;p&gt;参考&lt;a href=&quot;http://flume.apache.org/FlumeUserGuide.html&quot;&gt;官文文档&lt;/a&gt;&lt;br /&gt;
模式一:单输入单输出 &lt;br /&gt;
    &lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180502120225.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模式二:多flume连接
    &lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180502120550.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模式三:多输入汇总
    &lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180502120652.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模式四:多输出分发
    &lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180502120712.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;flume-角色&quot;&gt;Flume 角色&lt;br /&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;1、Source &lt;br /&gt;
  用于采集数据，Source 是产生数据流的地方，同时 Source 会将产生的数据流传输到 Channel，
  这个有点类似于 Java IO 部分的 Channel。&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;2、Channel&lt;br /&gt;
  用于桥接 Sources 和 Sinks，类似于一个队列。&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;3、Sink&lt;br /&gt;
  从 Channel 收集数据，将数据写到目标源(可以是下一个 Source，也可以是 HDFS 或者 HBase)。&lt;/li&gt;
  &lt;li&gt;4、Event&lt;br /&gt;
  传输单元，Flume 数据传输的基本单元，以事件的形式将数据从源头送至目的地&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;安装&quot;&gt;安装&lt;/h3&gt;

&lt;p&gt;下载官方对应的安装包,解压&lt;br /&gt;
修改 conf/flume-env.sh 文件中JAVA_HOME即可使用&lt;br /&gt;
本文使用的版本:1.7.0 下载地址: &lt;a href=&quot;http://archive.apache.org/dist/flume/&quot;&gt;官方下载地址&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;遇到的问题&quot;&gt;遇到的问题:&lt;/h3&gt;
&lt;p&gt;在flume中配置两个sink输出到指定两端口,然后用两个soureces去接受这两个sink传递过来的值,,最终将之前其中一个sink的发送的数据放到hdfs,另一个数据放到本地磁盘.但是放到本地磁盘的那份数据,只有目录和文件,数据没有,放到hdfs上的有数据&lt;br /&gt;
第一个flume的配置&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 讲一个source 分发给多个chanel-对应多个sink，给下一个相应的flume
a1.sources = r1
a1.channels = c1 c2
a1.sinks = k1 k2

# 将数据复制给多个channel
a1.sources.r1.selector.type = replicating

# sources 设置
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /home/admin/module/hive-1.2.2/logs/hive.log
a1.sources.r1.shell = /bin/bash -c

#channels 设置
# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.channels.c2.type = memory
a1.channels.c2.capacity = 1000
a1.channels.c2.transactionCapacity = 100

# sinks 设置
a1.sinks.k2.type = avro
a1.sinks.k2.hostname = hd001
a1.sinks.k2.port = 8088
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hd001
a1.sinks.k1.port = 8089  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;第二个flume的配置&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#接受上一个flume 的sink的结果# 定义服务
a2.sources = r1
a2.channels = c1
a2.sinks = k1

# source 设置
a2.sources.r1.type = avro
a2.sources.r1.bind = hd001
a2.sources.r1.port = 8089

# sink 设置
a2.sinks.k1.type = hdfs
a2.sinks.k1.hdfs.path = hdfs://192.168.1.20:9000/flume4/manysinks/%Y%m%d/%H
#上传文件的前缀
a2.sinks.k1.hdfs.filePrefix = upload2-
#是否按照时间滚动文件夹
a2.sinks.k1.hdfs.round = true
#多少时间单位创建一个新的文件夹
a2.sinks.k1.hdfs.roundValue = 1
#重新定义时间单位
a2.sinks.k1.hdfs.roundUnit = hour
#是否使用本地时间戳
a2.sinks.k1.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
a2.sinks.k1.hdfs.batchSize = 1000
#设置文件类型，可支持压缩
a2.sinks.k1.hdfs.fileType = DataStream
#多久生成一个新的文件
a2.sinks.k1.hdfs.rollInterval = 600
#设置每个文件的滚动大小
a2.sinks.k1.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
a2.sinks.k1.hdfs.rollCount = 0
#最小冗余数
a2.sinks.k1.hdfs.minBlockReplicas = 1


# Use a channel which buffers events in memory
a2.channels.c1.type = memory
a2.channels.c1.capacity = 1000
a2.channels.c1.transactionCapacity = 100

a2.sources.r1.channels = c1
a2.sinks.k1.channel = c1

a1.sources.r1.channels = c1 c2
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;第三个flume的配置&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#接受上一个flume 的sink的结果# 定义服务
a3.sources = r1
a3.channels = c1
a3.sinks = k1
# source 设置
a3.sources.r1.type = avro
a3.sources.r1.bind = hd001
a3.sources.r1.port = 8088
# sink 设置
a3.sinks.k1.type = file_roll
a3.sinks.k1.sink.directory = /home/admin/tmp/flume4
# Use a channel which buffers events in memory
a3.channels.c1.type = memory
a3.channels.c1.capacity = 100
a3.channels.c1.transactionCapacity = 50

a3.sources.r1.cahnnels = c1
a3.sinks.k1.channel = c1  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;查看第三个flume配置中对应结果目录数据&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[admin@hd001 ~]$ ll tmp/flum4/
总用量 0
-rw-rw-r--. 1 admin admin 0 5月   2 11:32 1525231977673-1
-rw-rw-r--. 1 admin admin 0 5月   2 11:37 1525231977673-10
-rw-rw-r--. 1 admin admin 0 5月   2 11:37 1525231977673-11
-rw-rw-r--. 1 admin admin 0 5月   2 11:38 1525231977673-12
-rw-rw-r--. 1 admin admin 0 5月   2 11:39 1525231977673-13
-rw-rw-r--. 1 admin admin 0 5月   2 11:39 1525231977673-14
-rw-rw-r--. 1 admin admin 0 5月   2 11:39 1525231977673-15
-rw-rw-r--. 1 admin admin 0 5月   2 11:40 1525231977673-16
-rw-rw-r--. 1 admin admin 0 5月   2 11:41 1525231977673-17
-rw-rw-r--. 1 admin admin 0 5月   2 11:41 1525231977673-18
-rw-rw-r--. 1 admin admin 0 5月   2 11:41 1525231977673-19
里面的数据为0,cat * 出来也是空的,但是在第二个flume中到hdfs上的数据是有对应的hive.log日志

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;</content><author><name>liushan</name></author><summary type="html">flume 简介: 百度百科: Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。 当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。 简介2 1) Flume 提供一个分布式的，可靠的，对大数据量的日志进行高效收集、聚集、移动的服务， Flume 只能在 Unix 环境下运行。 2) Flume 基于流式架构，容错性强，也很灵活简单。 3) Flume、Kafka 用来实时进行数据收集，Spark、Storm 用来实时处理数据，impala 用来实 时查询。</summary></entry><entry><title type="html">hadoop-HA(高可用)集群搭建</title><link href="http://localhost:4000/2018/04/16/hadoop-HA(%E9%AB%98%E5%8F%AF%E7%94%A8)%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/" rel="alternate" type="text/html" title="hadoop-HA(高可用)集群搭建" /><published>2018-04-16T00:00:00+08:00</published><updated>2018-04-16T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/16/hadoop-HA(%E9%AB%98%E5%8F%AF%E7%94%A8)%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA</id><content type="html" xml:base="http://localhost:4000/2018/04/16/hadoop-HA(%E9%AB%98%E5%8F%AF%E7%94%A8)%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">&lt;h4 id=&quot;准备工作&quot;&gt;准备工作&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;静态IP&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;映射主机名与ip&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;jdk环境&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;防火墙关闭&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;ssh免密&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;高可用原理介绍&quot;&gt;高可用原理介绍&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;为何使用ha&quot;&gt;为何使用HA&lt;br /&gt;&lt;/h5&gt;
    &lt;p&gt;因为在非HA集群模式下namenode是单节点工作,故存在namenode的单节点故障.&lt;br /&gt;
为防止故障发生,需要使用多个namenode节点.&lt;br /&gt;
其中,hadoop2.x版本只能支持2个namenode节点 ,hadoop3.x可以支持更多个&lt;br /&gt;
本文以hadoop2.7.2版本为基础
&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;ha实现原理&quot;&gt;HA实现原理&lt;/h5&gt;
    &lt;p&gt;两个namenode的数据是一致的.&lt;br /&gt;
两个namenode通过hadoop中的journalnode集群服务来同步两个namenode的元数据&lt;br /&gt;
两个namenode工作时,其中一台处于active状态,另外一台处于standy状态,否则会出现(split-brain)脑裂,集群无法工作.&lt;br /&gt;
在故障自动转移中, 通过 zookeeper 中的ZKFC(zookeeper failover controller,zookeeper 故障转移控制)进程来控制namenode节点的工作状态切换&lt;br /&gt;
其中ZKFC会在两个namenode节点只监听namenode的状态信息,不会对元数据进行操作,&lt;br /&gt;
当处于active的namenode宕机或死掉,zookeeper会通过ZKFC通知另外一台namenode启用(active)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;namenode的高可用配置&quot;&gt;namenode的高可用配置&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;1解压或复制原来hadoop集群相关文件&quot;&gt;1.解压或复制原来hadoop集群相关文件&lt;br /&gt;&lt;/h5&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  tar -zxf hadoop-2.7.2.tar.gz -C ~/module/HA/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;2配置hadoop相关文件&quot;&gt;2.配置hadoop相关文件&lt;/h5&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  cd /home/admin/module/HA/hadoop-2.7.2/etc/hadoop    
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑core-sitexml此时为非自动故障转移&quot;&gt;编辑core-site.xml(此时为非自动故障转移)&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;configuration&amp;gt;
    &amp;lt;!-- 把两个NameNode）的地址组装成一个集群haCluster(haCluster为集群名称,后续需要跟此保持一致) --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hdfs://haCluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- # dfs 系统存取数据的目录 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/admin/module/HA/hadoop-2.7.2/data/tmp&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- journalnode 数据存储目录 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.journalnode.edit.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/home/admin/module/HA/hadoop-2.7.2/jn/haCluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- zookeeper通信客户端地址  --&amp;gt;
    &amp;lt;!-- &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;ha.zookeeper.quorum&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hd001:2181,hd002:2181,hd003:2181&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;  --&amp;gt;

  &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑hdfs-sitexml&quot;&gt;编辑hdfs-site.xml&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;configuration&amp;gt;
    &amp;lt;!-- 完全分布式集群名称 haCluster 此处的haCluster与core-site.xmlvs中的集群名称需要一致,此xml种的haCluster都是集群对应的名称 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.nameservices&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;haCluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 集群中NameNode节点都有哪些 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.namenodes.haCluster&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;nn1,nn2&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- nn1的RPC通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.rpc-address.haCluster.nn1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd002:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

     &amp;lt;!-- nn2的RPC通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.rpc-address.haCluster.nn2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd003:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- nn1的http通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.http-address.haCluster.nn1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd002:50070&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- nn2的http通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.http-address.haCluster.nn2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd003:50070&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.shared.edits.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;qjournal://hd001:8485;hd002:8485;hd003:8485/haCluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
   &amp;lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.fencing.methods&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;sshfence&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 使用隔离机制时需要ssh无秘钥登录--&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.private-key-files&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/home/admin/.ssh/id_rsa&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 声明journalnode服务器存储目录--&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.journalnode.edits.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/home/admin/module/HA/hadoop-2.7.2/jn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 关闭权限检查--&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.permissions.enable&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.client.failover.proxy.provider.haCluster&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- # hdfs文件系统中的文件副本数量 为1(一般情况,完全分布式都是3分以上基数份) --&amp;gt;
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- # hdfs文件系统中的文件副本数量 为1(一般情况,完全分布式都是3分以上基数份) --&amp;gt;
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- # 节点检测频率,用户namenode 检测datanode是否存活 120s --&amp;gt;
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.namenode.checkpoint.period&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;120&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- 启用web查看hdfs系统 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.webhdfs.enabled&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- 启用自动故障转移 --&amp;gt;
    &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- # 指定 dfs 相关的机器地址,用户上下线新的机器 --&amp;gt;
    &amp;lt;!-- &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.hosts&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    # 指定退役的节点
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.hosts.exclude&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt; --&amp;gt;
  &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑mapred-sitexml&quot;&gt;编辑mapred-site.xml&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;configuration&amp;gt;
      &amp;lt;!-- 指定mr运行在yarn上 --&amp;gt;
        &amp;lt;property&amp;gt;
                &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
                &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
        &amp;lt;/property&amp;gt;

        &amp;lt;!--配置历史服务器 --&amp;gt;
        &amp;lt;property&amp;gt;
                &amp;lt;name&amp;gt;mapreduce.jobhistory.address&amp;lt;/name&amp;gt;
                &amp;lt;value&amp;gt;hd001:10020&amp;lt;/value&amp;gt;
        &amp;lt;/property&amp;gt;
        &amp;lt;property&amp;gt;
                &amp;lt;name&amp;gt;mapreduce.jobhistory.webapp.address&amp;lt;/name&amp;gt;
                &amp;lt;value&amp;gt;hd001:19888&amp;lt;/value&amp;gt;
        &amp;lt;/property&amp;gt;

  &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;将hadoop目录分发至集群每台机器&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  scp -r /home/admin/module/HA/hadoop-2.7.2 hd002:~/module/HA/
  scp -r /home/admin/module/HA/hadoop-2.7.2 hd003:~/module/HA/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;至此 namenode高可用搭建完成,但是不是自动故障转移,切换namenode的active状态需要手动&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑yarn-sitexml此处为非自动故障转移的配置&quot;&gt;编辑yarn-site.xml(此处为非自动故障转移的配置)&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &amp;lt;!-- 指定YARN的ResourceManager的地址 --&amp;gt;
    &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;hd002&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
      &amp;lt;!-- 日志聚集功能使能 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
      &amp;lt;!-- 日志保留时间设置7天 7*24*60*60 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log-aggregation.retain-seconds&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;604800&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!-- 日志储存地址 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log.server.url&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;http://hd001:19888/jobhistory/logs&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑-slaves&quot;&gt;编辑 slaves&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  hd001
  hd002
  hd003
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;namenode高可用测试&quot;&gt;namenode高可用测试&lt;/h5&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;首先启动集群journalnode集群服务&quot;&gt;首先启动集群journalnode集群服务&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  #需要启动每个节点的 journalnode 
  $ cd /home/admin/module/HA/hadoop-2.7.2
  $ sbin/hadoop-daemon.sh start journalnode
  $ jps
      7684 Jps
      7609 JournalNode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;格式化namenode&quot;&gt;格式化namenode&lt;/h6&gt;
        &lt;font color=&quot;red&quot;&gt;注意: 为了使journalnode服务记录namenode初始信息,在格式化namenode前,需要先将journalnode集群服务启动,否则会失败&lt;/font&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  $ bin/hdfs namenode -format
  #  Storage directory /home/admin/module/HA/hadoop-2.7.2/data/tmp/dfs/name has been successfully formatted.
  #  出现这句话时,表示format成功
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;启动nn1的namenode&quot;&gt;启动nn1的namenode&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  sbin/hadoop-daemon.sh start namenode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;nn2同步nn1-的元数据信息&quot;&gt;nn2同步nn1 的元数据信息&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  bin/hdfs namenode -bootstrapStandby

&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;启动nn2的namenode&quot;&gt;启动nn2的namenode&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  sbin/hadoop-daemon.sh start namenode

&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;启动各个节点的datanode&quot;&gt;启动各个节点的datanode&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  # 每隔节点都需要启动 hd001 hd002 hd003
  $ sbin/hadoop-daemon.sh start datanode 

  $ sh ~/jpsutil.sh
  =========== admin@hd001 ============
  11010 DataNode
  11400 Jps
  10286 JournalNode
  =========== admin@hd002 ============
  9744 Jps
  9473 DataNode
  9317 NameNode
  8959 JournalNode
  =========== admin@hd003 ============
  8881 DataNode
  8388 JournalNode
  9161 Jps
  8746 NameNode

  #hd002,hd003中的namenode启动成功
  # 此时 访问 http://hd002:50070/  和 http://hd003:50070/  均发现两个节点处于 standy状态
  # 访问http://hd002:50070/explorer.html#/ 文件目录会提示时: 
  Operation category READ is not supported in state standby
  因为没有active的name造成的

&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;手动激活nn1中的namenode到active&quot;&gt;手动激活nn1中的namenode到active&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  bin/hdfs haadmin -transitionToActive nn1
  #此时再访问 http://hd002:50070/dfshealth.html#tab-overview 显示节点处于active
  访问 http://hd002:50070/explorer.html#/ 可以正常访问
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;手动激活nn2中的namenode到active&quot;&gt;手动激活nn2中的namenode到active&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  bin/hdfs haadmin -transitionToActive nn2
  Automatic failover is enabled for NameNode at hd002/192.168.1.21:9000
  Refusing to manually manage HA state, since it may cause
  a split-brain scenario or other incorrect state.
  If you are very sure you know what you are doing, please
  specify the --forcemanual flag.

  如果使用
  bin/hdfs haadmin -transitionToActive nn2  --forcemanual
  会提示 nn1已经处于active 不会被切换,切换失败
  18/04/16 18:56:57 WARN ha.HAAdmin: Proceeding with manual HA state management even though
  automatic failover is enabled for NameNode at hd002/192.168.1.21:9000
  transitionToActive: Node nn1 is already active
  Usage: haadmin [-transitionToActive [--forceactive] &amp;lt;serviceId&amp;gt;]
    
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;手动激活nn1中的namenode到standby&quot;&gt;手动激活nn1中的namenode到standby&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  bin/dfs haadmin -transitionToStandby nn1
  # 切换完后后,再切换nn2到active可成功切换
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ha的自动故障转移&quot;&gt;HA的自动故障转移&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    以上测试了手动故障转移的方式,下面配置自动故障转移&amp;lt;br&amp;gt;
    HA的自动故障转移依赖于zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;配置zookeeper&quot;&gt;配置zookeeper&lt;/h5&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  tar -zxvf zookeeper-3.4.10.tar.gz ~/module/HA/
  cd ~/module/HA/zookeeper-3.4.10/
  mkdir zkData
  cd zkData
  echo 1 &amp;gt; myid
  cd ../conf/
  mv zoo_simple.cfg zoo.cfg
  vim zoo.cfg
  # 修改dataDir 
  dataDir=/home/admin/module/HA/zookeeper-3.4.10/zkData
  #末尾增加
  server.1=hd001:2888:3888
  server.2=hd002:2888:3888
  server.3=hd003:2888:3888

  #保存退出
  #将 zookeeper分发到各个节点,修改zkData下myid文件中的值,于主机名称对应
  scp -r ~/module/HA/zookeeper-3.4.10  hd002:~/module/HA/
  scp -r ~/module/HA/zookeeper-3.4.10  hd003:~/module/HA/

&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;至此,zookeeper配置完成&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;zookeeper启动测试&quot;&gt;zookeeper启动测试&lt;/h5&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  #每台节点启动zookeeper服务
  cd /home/admin/module/HA/zookeeper-3.4.10/
  bin/zkServer.sh start
  #查看进程
  [admin@hd001 zookeeper-3.4.10]$ sh ~/jpsutil.sh
  =========== admin@hd001 ============
  14452 Jps
  14390 QuorumPeerMain
  13033 DataNode
  10286 JournalNode
  =========== admin@hd002 ============
  11785 DataNode
  13291 Jps
  11164 NameNode
  13230 QuorumPeerMain
  8959 JournalNode
  =========== admin@hd003 ============
  12817 QuorumPeerMain
  8388 JournalNode
  10892 NameNode
  12879 Jps
  #在其中一台启动zkCli.sh连接服务
  ls /

&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;hdfs-sitexml增加配置&quot;&gt;hdfs-site.xml增加配置&lt;/h5&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;core-site增加配置&quot;&gt;core-site增加配置&lt;/h5&gt;
    &lt;p&gt;在 core-site.xml 增加&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      &amp;lt;!-- zookeeper通信客户端地址  --&amp;gt;
      &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;ha.zookeeper.quorum&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd001:2181,hd002:2181,hd003:2181&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;故障自动转移完成&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;故障自动转移测试&quot;&gt;故障自动转移测试&lt;/h5&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  - 先停掉节点&amp;lt;br&amp;gt;
  sbin/stop-dfs.sh 

  - 初始化HA在Zookeeper中状态：&amp;lt;br&amp;gt;
  bin/hdfs zkfc -formatZK

  - 启动journalnode&amp;lt;br&amp;gt;
  sbin/hadoop-daemon.sh start journalnode

  - 启动dfs&amp;lt;br&amp;gt;
  sbin/start-dfs.sh &amp;lt;br&amp;gt;
  查看hd002:50070和hd003:50070,其中一台处于active
    
  - kill active namenode &amp;lt;br&amp;gt;
  sbin/hadoop-daemon.sh stop namenode &amp;lt;br&amp;gt;
  查看hd002:50070和hd003:50070,刚刚处于standby的namoenode自动切换为active了.
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;配置yarn-resourcemanager高可用&quot;&gt;配置yarn-resourcemanager高可用&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;编辑yarn-site.xml
    &lt;blockquote&gt;
      &lt;p&gt;可参考 &lt;a href=&quot;http://hadoop.apache.org/docs/r2.7.5/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html&quot; target=&quot;_blank&quot;&gt;Resourcemanager-HA官方文档&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;configuration&amp;gt;
      &amp;lt;!-- reducer获取数据的方式 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--启用resourcemanager ha--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.ha.enabled&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--声明两台resourcemanager的地址--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.cluster-id&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;cluster-yarn1&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.ha.rm-ids&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;rm1,rm2&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm1&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;hd001&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm2&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;hd002&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--指定zookeeper集群的地址--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.zk-address&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;hd001:2181,hd001:2181,hd001:2181&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--启用自动恢复--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.recovery.enabled&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.store.class&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
      &amp;lt;!-- 日志聚集功能使能 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
      &amp;lt;!-- 日志保留时间设置7天 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log-aggregation.retain-seconds&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;604800&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log.server.url&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;http://hd001:19888/jobhistory/logs&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
  &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;配置完成,分发文件&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;rm1启动yarn集群
  sbin/start-yarn.sh&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;rm2启动resourcemanager
  sbin/yarn-daemon.sh start resourcemanager &lt;br /&gt;
      &lt;font color=&quot;red&quot;&gt;注意:&lt;br /&gt;
          1.rm2的resourcemanager不会同yarn集群一起启动,需要单独启动;&lt;br /&gt;
          2.yarn的resourcemanager的HA,不会经过ZKFC控制,是通过yarn集群自己进行自动切换的&lt;/font&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;查看集群进程
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  sh ~/jpsutil.sh
  [admin@hd001 hadoop-2.7.2]$ sh ~/jpsutil.sh
  =========== admin@hd001 ============
  27937 ResourceManager
  24390 QuorumPeerMain
  27160 JournalNode
  27513 NodeManager
  28026 Jps
  26894 DataNode
  =========== admin@hd002 ============
  27505 ResourceManager
  27271 DFSZKFailoverController
  28232 Jps
  27659 NodeManager
  22556 QuorumPeerMain
  27116 JournalNode
  26988 DataNode
  26861 NameNode
  =========== admin@hd003 ============
  25202 JournalNode
  25074 DataNode
  24968 NameNode
  25595 NodeManager
  22092 QuorumPeerMain
  26044 Jps
  25357 DFSZKFailoverController
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;可访问 rm1 和 rm2, hd002:8088  hd003:8088&lt;br /&gt;
本文中 rm2 hd002处于activ中, 当访问hd001:8088时,会自动重定向到 hd002:8088/cluster&lt;br /&gt;
当将 rm2 停止 后,rm1处于active中&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;附件&quot;&gt;附件&lt;/h4&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;h5 id=&quot;图解hadoop-ha&quot;&gt;图解hadoop-HA&lt;/h5&gt;
        &lt;p&gt;&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180416172754.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h5 id=&quot;jpsutilsh&quot;&gt;jpsutil.sh&lt;/h5&gt;
        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;i &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;admin@hd001 admin@hd002 admin@hd003
  &lt;span class=&quot;k&quot;&gt;do
          &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;=========== &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; ============&quot;&lt;/span&gt;
          ssh &lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'jps'&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;hadoop-ha官方文档地址&quot;&gt;hadoop-HA&lt;a href=&quot;http://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html&quot; target=&quot;_blank&quot;&gt;官方文档地址&lt;/a&gt;&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>liushan</name></author><summary type="html">准备工作 静态IP 映射主机名与ip jdk环境 防火墙关闭 ssh免密</summary></entry><entry><title type="html">博客图床上传工具推荐</title><link href="http://localhost:4000/2018/04/16/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E4%B8%8A%E4%BC%A0%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/" rel="alternate" type="text/html" title="博客图床上传工具推荐" /><published>2018-04-16T00:00:00+08:00</published><updated>2018-04-16T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/16/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E4%B8%8A%E4%BC%A0%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90</id><content type="html" xml:base="http://localhost:4000/2018/04/16/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E4%B8%8A%E4%BC%A0%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/">&lt;h4 id=&quot;推荐的图床&quot;&gt;推荐的图床&lt;/h4&gt;
&lt;p&gt;最近在怼博客,然后需要一些图片来辅助完成记录,网上口碑较好的又拍(upyun),七牛等.
同事个人在用upyun,公司也用的是这个.所以选择了upyun,然后发现没有一些上传图床的工具都是收费.
找到一个开源的,共享之.&lt;/p&gt;

&lt;h4 id=&quot;开源图床picgo&quot;&gt;开源图床picGo&lt;/h4&gt;
&lt;p&gt;picGo支持的图床如下图&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;截图
&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180416174254.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;下载地址 &lt;br /&gt;
工具&lt;a href=&quot;https://github.com/Molunerfinn/PicGo/releases&quot; target=&quot;_blank&quot;&gt;github下载地址&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>liushan</name></author><summary type="html">推荐的图床 最近在怼博客,然后需要一些图片来辅助完成记录,网上口碑较好的又拍(upyun),七牛等. 同事个人在用upyun,公司也用的是这个.所以选择了upyun,然后发现没有一些上传图床的工具都是收费. 找到一个开源的,共享之.</summary></entry><entry><title type="html">zookeeper集群搭建</title><link href="http://localhost:4000/2018/04/13/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/" rel="alternate" type="text/html" title="zookeeper集群搭建" /><published>2018-04-13T00:00:00+08:00</published><updated>2018-04-13T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/13/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA</id><content type="html" xml:base="http://localhost:4000/2018/04/13/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">&lt;h2 id=&quot;准备工作&quot;&gt;准备工作&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;jdk环境&lt;/li&gt;
  &lt;li&gt;zookeeper安装包(本文使用的是zookeeper-3.4.10 版本) 可到&lt;a href=&quot;http://zookeeper.apache.org/releases.html&quot; target=&quot;_blank&quot;&gt;Zookeeper官网&lt;/a&gt;下载&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;步骤&quot;&gt;步骤&lt;/h2&gt;
&lt;h4 id=&quot;1解压文件&quot;&gt;1.解压文件&lt;/h4&gt;
&lt;p&gt;解压目标路径 /home/admin/module&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tar -zxvf zookeeper-3.4.10.tar.gz -C /home/admin/module/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;2修改配置&quot;&gt;2.修改配置&lt;/h4&gt;
&lt;p&gt;进入到zookeeper-3.4.10目录修改相关位置&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home/admin/module/zookeeper-3.4.10
mkdir zkData
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;conf
mv zoo_sample.cfg zoo.cfg
vim zoo.cfg
&lt;span class=&quot;nv&quot;&gt;dataDir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/admin/module/zookeeper-3.4.10/zkData
保存退出

&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ../zkData
&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;2 &amp;gt; myid
&lt;span class=&quot;c&quot;&gt;## 最后一行下面增加&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## 配置集群服务地址&lt;/span&gt;
server.2&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hd001:2888:3888
server.3&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hd002:2888:3888
server.4&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hd003:2888:3888

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h5 id=&quot;配置参数解读&quot;&gt;配置参数解读&lt;/h5&gt;
&lt;p&gt;Server.A=B:C:D。 &lt;br /&gt;
A是一个数字，表示这个是第几号服务器； &lt;br /&gt;
B是这个服务器的ip地址； &lt;br /&gt;
C是这个服务器与集群中的Leader服务器交换信息的端口； &lt;br /&gt;
D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的 &lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3分发文件&quot;&gt;3.分发文件&lt;/h4&gt;
&lt;p&gt;完成以上配置后,将此目录分发到其他机器节点&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync -rvl /home/admin/module/zookeeper-3.4.10 hd002:~/module/
rsync -rvl /home/admin/module/zookeeper-3.4.10 hd003:~/module/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;font color=&quot;red&quot;&gt;分发完成后修改对应文件 zookeeper-3.4.10/zkData/myid 中对应的值 ,&lt;br /&gt;
其中 myid 文件中的值与 server.3=hd002:2888:3888,server.3中的3对应
&lt;/font&gt;

&lt;h5 id=&quot;-注意&quot;&gt;&lt;font color=&quot;red&quot;&gt; 注意&lt;/font&gt;&lt;/h5&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1]scp -r /home/admin/module/zookeeper-3.4.10 hd002:~/module/
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2]scp -r /home/admin/module/zookeeper-3.4.10/ hd002:~/module/
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1],[2]效果一样

&amp;lt;1&amp;gt;/rsync -rvl /home/admin/module/zookeeper-3.4.10 hd002:~/module/
&amp;lt;2&amp;gt;rsync -rvl /home/admin/module/zookeeper-3.4.10/ hd002:~/module/
&lt;span class=&quot;gp&quot;&gt;&amp;lt;1&amp;gt;&amp;lt;2&amp;gt; &lt;/span&gt;是不同的
&amp;lt;1&amp;gt;中是将整个目录和目录下所有文件分发给hd002,会在hd002:~/module/下创建一个新的zookeeper-3.4.10目录并将文件同步过去
&amp;lt;2&amp;gt;是将整个目录下所有文件分发给hd001,不会将目录本身分发出去

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;4启动和查看命令&quot;&gt;4.启动和查看命令&lt;/h4&gt;
&lt;p&gt;需要分别到每台服务进行启动&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# hd001&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home/admin/module/zookeeper-3.4.10
bin/zkServer.sh start
bin/zkServer.sh status
&lt;span class=&quot;c&quot;&gt;#状态结果&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;admin@hd001 zookeeper-3.4.10]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /home/admin/module/zookeeper-3.4.10/bin/../conf/zoo.cfg
Mode: follower

&lt;span class=&quot;c&quot;&gt;# hd002&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home/admin/module/zookeeper-3.4.10
bin/zkServer.sh start
bin/zkServer.sh status
&lt;span class=&quot;c&quot;&gt;#状态结果(因本地已经重启过很多次 .此台机器第一次按顺序启动将会被选举为 leader的)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;admin@hd002 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./module/zookeeper-3.4.10/bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /home/admin/module/zookeeper-3.4.10/bin/../conf/zoo.cfg
Mode: follower
&lt;span class=&quot;c&quot;&gt;# hd003&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home/admin/module/zookeeper-3.4.10
bin/zkServer.sh start
bin/zkServer.sh status
&lt;span class=&quot;c&quot;&gt;#状态结果&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;admin@hd003 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./module/zookeeper-3.4.10/bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /home/admin/module/zookeeper-3.4.10/bin/../conf/zoo.cfg
Mode: leader
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;</content><author><name>liushan</name></author><summary type="html">准备工作 jdk环境 zookeeper安装包(本文使用的是zookeeper-3.4.10 版本) 可到Zookeeper官网下载</summary></entry><entry><title type="html">macos装虚拟机NAT网络互ping问题</title><link href="http://localhost:4000/2018/04/12/macos%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BANAT%E7%BD%91%E7%BB%9C%E4%BA%92ping%E9%97%AE%E9%A2%98/" rel="alternate" type="text/html" title="macos装虚拟机NAT网络互ping问题" /><published>2018-04-12T00:00:00+08:00</published><updated>2018-04-12T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/12/macos%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BANAT%E7%BD%91%E7%BB%9C%E4%BA%92ping%E9%97%AE%E9%A2%98</id><content type="html" xml:base="http://localhost:4000/2018/04/12/macos%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BANAT%E7%BD%91%E7%BB%9C%E4%BA%92ping%E9%97%AE%E9%A2%98/">&lt;h3 id=&quot;问题描述&quot;&gt;问题描述&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;macOS系统装虚拟机,虚拟机与宿主机互ping不通&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;解决方案&quot;&gt;解决方案&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;修改宿主机的VMware网络设置&lt;/li&gt;
  &lt;li&gt;编辑文件目录
    &lt;blockquote&gt;
      &lt;p&gt;/Library/Preferences/VMware Fusion/networking
内容如下&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1,0
&lt;span class=&quot;c&quot;&gt;# 此处禁用DHCP模式&lt;/span&gt;
answer VNET_1_DHCP no
answer VNET_1_DHCP_CFG_HASH A1C3DC05C0F343C380B049B0A45A95DD63494961
answer VNET_1_HOSTONLY_NETMASK 255.255.255.0
answer VNET_1_HOSTONLY_SUBNET 192.168.181.0
&lt;span class=&quot;c&quot;&gt;# 宿主机的ip地址&lt;/span&gt;
answer VNET_1_VIRTUAL_ADAPTER yes
answer VNET_1_VIRTUAL_ADAPTER_ADDR 10.10.1.67
&lt;span class=&quot;c&quot;&gt;# 禁用DHCP模式&lt;/span&gt;
answer VNET_8_DHCP no
answer VNET_8_DHCP_CFG_HASH 5197E3A254D370D2E0B1CCD8B3F59319D3A67453
&lt;span class=&quot;c&quot;&gt;# 子网掩码&lt;/span&gt;
answer VNET_8_HOSTONLY_NETMASK 255.255.255.0
&lt;span class=&quot;c&quot;&gt;# 子网网段 192.168.1.0-192.168.255.0&lt;/span&gt;
answer VNET_8_HOSTONLY_SUBNET 192.168.1.0
answer VNET_8_NAT yes
answer VNET_8_VIRTUAL_ADAPTER yes
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>liushan</name></author><summary type="html">问题描述 macOS系统装虚拟机,虚拟机与宿主机互ping不通</summary></entry><entry><title type="html">hadoop完全分布式环境搭建</title><link href="http://localhost:4000/2018/04/09/hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F)%E4%B8%80/" rel="alternate" type="text/html" title="hadoop完全分布式环境搭建" /><published>2018-04-09T00:00:00+08:00</published><updated>2018-04-09T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/09/hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F)%E4%B8%80</id><content type="html" xml:base="http://localhost:4000/2018/04/09/hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F)%E4%B8%80/">&lt;h2 id=&quot;准备工作&quot;&gt;准备工作:&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;三台或三台以上机器(本文以三台虚拟机为例)
    &lt;blockquote&gt;

      &lt;p&gt;centOS 6.8&lt;/p&gt;

      &lt;p&gt;VMware Fusion 10.1(maxos的虚拟机版本),window下推荐VMware 12或14稳定版&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;每台机器安装jdk,hadoop,并配置相应的环境变量
    &lt;blockquote&gt;

      &lt;p&gt;jdk 1.8&lt;/p&gt;

      &lt;p&gt;hadoop 2.7.2&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;安装规划&quot;&gt;安装规划&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;系统中新建个非root用户, 并且 将此用户修改用户root权限&lt;/li&gt;
  &lt;li&gt;所需安装文件全部存于/opt/software目录中&lt;/li&gt;
  &lt;li&gt;所有软件安装到  /opt/module目录下&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改/opt目录的拥有者  chgroup hadoop hdaoop&lt;/p&gt;

    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;主机&lt;/td&gt;
          &lt;td&gt;hadoop101&lt;/td&gt;
          &lt;td&gt;hadoop102&lt;/td&gt;
          &lt;td&gt;hadoop103&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;角色&lt;/td&gt;
          &lt;td&gt;namenode&lt;/td&gt;
          &lt;td&gt;datanode&lt;/td&gt;
          &lt;td&gt;datanode&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;datanode&lt;/td&gt;
          &lt;td&gt;resourcemanager&lt;/td&gt;
          &lt;td&gt;nodemanager&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;nodemanager&lt;/td&gt;
          &lt;td&gt;nodemanager&lt;/td&gt;
          &lt;td&gt;secondaryNameNode&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;机器设置&quot;&gt;机器设置&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;配置三台机器的ip为静态ip,并能够互相ping通,且能ping通外网&lt;/li&gt;
  &lt;li&gt;以下已一台机器为例&lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;新建用户&quot;&gt;新建用户&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;新建nginx用户并增加到nginx工作组,-g后跟组名 组和用户名都为hadoop,也可更改为其他用户名
useradd -g hadoop hadoop  (后续文章都以hadoop用户登录系统做操作)&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1、建用户：
adduser 用户名                           //新建用户
passwd 用户名                           //给用户设置密码
2、建工作组
groupadd 组名                         //新建工作组
3、新建用户同时增加工作组
useradd -g nginx nginx               //新建nginx用户并增加到nginx工作组,-g后跟组名
注：：-g 所属组 -d 家目录 -s 所用的SHELL
4、给已有的用户增加工作组
usermod -G groupname username
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;设置静态ip&quot;&gt;设置静态ip&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim /etc/sysconfig/network-scripts/ifcfg-eth0&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nv&quot;&gt;DEVICE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;eth0
  &lt;span class=&quot;nv&quot;&gt;TYPE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Ethernet
  &lt;span class=&quot;nv&quot;&gt;UUID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;c4fcd4b8-9338-4489-bee5-6797d077a036
  &lt;span class=&quot;nv&quot;&gt;NM_CONTROLLED&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
  &lt;span class=&quot;c&quot;&gt;# 设置静态ip地址&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;IPADDR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;192.168.1.102
  &lt;span class=&quot;c&quot;&gt;# 网关&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;GATEWAY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;192.168.1.2
  &lt;span class=&quot;nv&quot;&gt;NETMASK&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;255.255.255.0
  &lt;span class=&quot;c&quot;&gt;# 系统启动时启用&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;ONBOOT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
  &lt;span class=&quot;c&quot;&gt;# 设置为静态ip&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;BOOTPROTO&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;static
  &lt;span class=&quot;c&quot;&gt;# dns&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;DNS1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;114.114.114.114
  &lt;span class=&quot;nv&quot;&gt;PREFIX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;24
  &lt;span class=&quot;nv&quot;&gt;DEFROUTE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
  &lt;span class=&quot;nv&quot;&gt;IPV4_FAILURE_FATAL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
  &lt;span class=&quot;c&quot;&gt;# 禁用ipv6&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;IPV6INIT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;no
  &lt;span class=&quot;nv&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;System eth0&quot;&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# mac地址 对应 /etc/udev/rules.d/70-persistent-net.rules 中的 ATTR{address}的值&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR{address}==&quot;00:0c:29:d8:7f:e3&quot;, ATTR{type}==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth0&quot;&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;HWADDR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;00:0c:29:d8:7f:e3
  &lt;span class=&quot;nv&quot;&gt;LAST_CONNECT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1520522957
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;修改hostname&quot;&gt;修改hostname&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim /etc/sysconfig/network&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;NETWORKING&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
&lt;span class=&quot;nv&quot;&gt;HOSTNAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hadoop102
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;重启&quot;&gt;重启&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;sudo reboot -h now&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo reboot -h now 
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;修改其他机器的静态ip和hostname&quot;&gt;修改其他机器的静态ip和hostname&lt;/h4&gt;
    &lt;p&gt;此处忽略,可以参考第一台的设置&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;安装jdk-和-hadoop&quot;&gt;安装jdk 和 hadoop&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;下载jdk 和 hadoop压缩包存于 /opt/software目录中&lt;/li&gt;
  &lt;li&gt;将jdk压缩包,hadoop压缩包解到  /opt/module
    &lt;blockquote&gt;
      &lt;p&gt;tar -zxvf&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 解压命令&lt;/span&gt;
tar -zxvf /opt/software/jdk-8u144-linux-x64.tar.gz -C /opt/module
tar -zxvf /opt/software/hadoop-2.7.2.tar.gz -C /opt/module
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;配置JAVA_HOME和PATH ,编辑/etc/profile文件,最后一行添加如下
    &lt;blockquote&gt;
      &lt;p&gt;sudo vim /etc/profile&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/opt/module/jdk1.8.0_144
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/opt/module/hadoop-2.7.2
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/bin
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/sbin
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;检验是否安装成功
    &lt;blockquote&gt;
      &lt;p&gt;java -version&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java version &lt;span class=&quot;s2&quot;&gt;&quot;1.8.0_144&quot;&lt;/span&gt;
Java&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;TM&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; SE Runtime Environment &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;build 1.8.0_144-b01&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Java HotSpot&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;TM&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 64-Bit Server VM &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;build 25.144-b01, mixed mode&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
      &lt;p&gt;hadoop version&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Hadoop 2.7.2
Subversion Unknown -r Unknown
Compiled by root on 2017-05-22T10:49Z
Compiled with protoc 2.5.0
From &lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;with checksum d0fda26633fa762bff87ec759ebe689c
This &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;was run using /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;配置-hadoop&quot;&gt;配置 hadoop&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;进入到 /opt/module/hadoop-2.7.2/etc/hadoop 目录下&lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;编辑hadoop-envsh&quot;&gt;编辑hadoop-env.sh&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim hadoop-env.sh 配置JAVA_HOME&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/opt/module/jdk1.8.0_144
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;编辑hdfs-sitexml&quot;&gt;编辑hdfs-site.xml&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim hdfs-site.xml&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
          # hdfs文件系统中的文件副本数量 为3(一般情况,完全分布式都是3分以上基数份)
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # 第二名称辅助节点地址和端口
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.secondary.http-address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop104:50090&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # 节点检测频率,用户namenode 检测datanode是否存活 120s
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.checkpoint.period&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;120&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # namenode存name相关数据地址
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/module/hadoop-2.7.2/data/tmp/dfs/name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

          #多namenode的name目录,其中 name1 和name2的数据不会重复
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:///${hadoop.tmp.dir}/dfs/name1,file:///${hadoop.tmp.dir}/dfs/name2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # 指定 dfs 相关的机器地址,用户上下线新的机器
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.hosts&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # 指定退役的节点
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.hosts.exclude&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;编辑-core-sitexml&quot;&gt;编辑 core-site.xml&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim core-site.xml&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
      # dfs 的名称节点
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://hadoop102:9000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
      # dfs 系统存取数据的目录
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.trash.interval&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.http.staticuser.user&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;配置yarn-sitexml&quot;&gt;配置yarn-site.xml&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim yarn-site.xml&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- reducer获取数据的方式 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mapreduce_shuffle&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

          &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 指定YARN的ResourceManager的地址 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hd002&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 日志聚集功能使能 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.log-aggregation-enable&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 日志保留时间设置7天 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.log-aggregation.retain-seconds&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;604800&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;编辑maperd-sitexml&quot;&gt;编辑maperd-site.xml&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim maperd-site.xml&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 指定mr运行在yarn上 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.framework.name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;yarn&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

          &lt;span class=&quot;c&quot;&gt;&amp;lt;!--配置历史服务器 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.jobhistory.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop101:10020&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.jobhistory.webapp.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop101:19888&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;配置集群地址&quot;&gt;配置集群地址&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim slaves&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hadoop102
hadoop103
hadoop104
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;分发文件&quot;&gt;分发文件&lt;/h4&gt;
  &lt;/li&gt;
  &lt;li&gt;将/opt/moudle/目录下所有文件分发到其他机器
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;c&quot;&gt;# 可自定义脚本执行&lt;/span&gt;
  rsync -rvl /opt/moudle hadoop@hadoop102:/opt/moudle
  rsync -rvl /opt/moudle hadoop@hadoop103:/opt/moudle
  rsync -rvl /opt/moudle hadoop@hadoop104:/opt/moudle
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;将/etc/profile文件分发到其他机器
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; rsync -rvl /etc/profile hadoop@hadoop102:/etc
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;启动查看结果&quot;&gt;启动查看结果&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;hadoop101上 启动 dfs&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      sbin/start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;blockquote&gt;
      &lt;p&gt;hadoop102上 启动 yarn&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      sbin/start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;blockquote&gt;
      &lt;p&gt;查看结果&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  hadoop101&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jps
  36577 SecondaryNameNode
  38209 Jps
  35314 DataNode
  35604 NodeManager
  35160 NameNode

  hadoop102&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jps
  37283 NodeManager
  36981 ResourceManager
  36829 DataNode
  41519 Jps

  hadoop103&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jps
  36577 SecondaryNameNode
  36678 NodeManager
  36438 DataNode
  41403 Jps

&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;图解说明&quot;&gt;图解说明&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;图解namenode工作机制&quot;&gt;图解namenode工作机制&lt;/h4&gt;
    &lt;p&gt;&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180416172857.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;图解datanode工作机制&quot;&gt;图解datanode工作机制&lt;/h4&gt;
    &lt;p&gt;&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180416173056.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;图解yarn架构&quot;&gt;图解yarn架构&lt;/h4&gt;
    &lt;p&gt;&lt;img src=&quot;https://stone-upyun.b0.upaiyun.com/blog20180416173218.png!700x999&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;自定义脚本分发文件&quot;&gt;自定义脚本分发文件&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;新建自定义脚本文件 touch /usr/bin/xsync&lt;/p&gt;
  &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo chmod +x /usr/bin/xsync
vim /usr/bin/xsync
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;``` bash
#!/bin/bash
# 获取输入参数个数
pcount=$#
if((pcount==0));then
echo no args;
exit;
fi

# 获取文件名
p1=$1
fname=`basename $p1`
echo fname=$fname

# 获取上机目录到绝对路径

pdir=`cd -P $(dirname $p1); pwd`

echo pdir=$pdir

# 获取当前用户名
user=`whoami`

for((host=103;host&amp;lt;109;host++));do
        echo --------------------hadoop$host-----------------
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done

echo &quot;success&quot;
```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;</content><author><name>liushan</name></author><summary type="html">准备工作: 三台或三台以上机器(本文以三台虚拟机为例) centOS 6.8 VMware Fusion 10.1(maxos的虚拟机版本),window下推荐VMware 12或14稳定版 每台机器安装jdk,hadoop,并配置相应的环境变量 jdk 1.8 hadoop 2.7.2</summary></entry><entry><title type="html">本地jekyll-server启动证书错误问题</title><link href="http://localhost:4000/2018/04/09/%E6%9C%AC%E5%9C%B0jekyll-server%E5%90%AF%E5%8A%A8%E8%AF%81%E4%B9%A6%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98/" rel="alternate" type="text/html" title="本地jekyll-server启动证书错误问题" /><published>2018-04-09T00:00:00+08:00</published><updated>2018-04-09T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/09/%E6%9C%AC%E5%9C%B0jekyll-server%E5%90%AF%E5%8A%A8%E8%AF%81%E4%B9%A6%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98</id><content type="html" xml:base="http://localhost:4000/2018/04/09/%E6%9C%AC%E5%9C%B0jekyll-server%E5%90%AF%E5%8A%A8%E8%AF%81%E4%B9%A6%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98/">&lt;hr /&gt;

&lt;h3 id=&quot;问题描述&quot;&gt;问题描述:&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;本地启动jekyll server 博客时显示如下错误:&lt;/p&gt;
  &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Liquid Exception: SSL_connect &lt;span class=&quot;nv&quot;&gt;returned&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1 &lt;span class=&quot;nv&quot;&gt;errno&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &lt;span class=&quot;nv&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;error: certificate verify failed &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /_layouts/page.html
jekyll 3.6.2 | Error:  SSL_connect &lt;span class=&quot;nv&quot;&gt;returned&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1 &lt;span class=&quot;nv&quot;&gt;errno&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &lt;span class=&quot;nv&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;error: certificate verify failed    
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;解决方案&quot;&gt;解决方案:&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;1.下载一个证书 名称为: cacert.pem&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;2.将证书路径设置到系统变量中&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;window下 可使用命令 set SSL_CERT_FILE=d:/XmacZone/down/cacert.pem&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;linux 或macos 编制.brash 或.zshrc&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后一行添加 export  SSL_CERT_FILE=/Users/XmacZone/down/cacert.pem   ;执行命令 source ~/.zshrc 即可.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>liushan</name></author><summary type="html"></summary></entry><entry><title type="html">linux下恢复删除的文件</title><link href="http://localhost:4000/2017/07/18/linux%E4%B8%AD%E6%81%A2%E5%A4%8D%E5%88%A0%E9%99%A4%E7%9A%84%E6%96%87%E4%BB%B6/" rel="alternate" type="text/html" title="linux下恢复删除的文件" /><published>2017-07-18T00:00:00+08:00</published><updated>2017-07-18T00:00:00+08:00</updated><id>http://localhost:4000/2017/07/18/linux%E4%B8%AD%E6%81%A2%E5%A4%8D%E5%88%A0%E9%99%A4%E7%9A%84%E6%96%87%E4%BB%B6</id><content type="html" xml:base="http://localhost:4000/2017/07/18/linux%E4%B8%AD%E6%81%A2%E5%A4%8D%E5%88%A0%E9%99%A4%E7%9A%84%E6%96%87%E4%BB%B6/">&lt;h2 id=&quot;linuxubuntu修复删除的文件&quot;&gt;Linux(Ubuntu)修复删除的文件&lt;/h2&gt;

&lt;p&gt;本人基于Ubuntu server 16.04 环境下,其他linux系统类似.
作为一个初学者,难免有不小心删除文件的误操作,google了下,成功恢复了.&lt;/p&gt;

&lt;h3 id=&quot;查看自己的文件系统和分区&quot;&gt;查看自己的文件系统和分区&lt;/h3&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;hadoop@ubuntu-ser1:~/devapp$ &lt;/span&gt;df -T /home
Filesystem                        Type 1K-blocks    Used Available Use% Mounted on
/dev/mapper/ubuntu--ser1--vg-root ext4  18982780 3766336  14229104  21% /

&lt;span class=&quot;c&quot;&gt;## /dev/mapper/ubuntu--ser1--vg-root 就是当前系统所在分区  ext4是文件系统类型&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;安装恢复文件所需的软件extundelete&quot;&gt;安装恢复文件所需的软件extundelete&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt install extundelete -y

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;恢复文件&quot;&gt;恢复文件&lt;/h3&gt;
&lt;p&gt;跳转到一个目录,最好是不需要的目录,因为一会恢复的文件会恢复到这个目录;例如,我跳到了我刚刚删除文件的那个目录&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/devapp/

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后执行&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo extundelete /dev/mapper/ubuntu--ser1--vg-root --restore-all
&lt;span class=&quot;c&quot;&gt;## /dev/mapper/ubuntu--ser1--vg-root 这个是文件所在的分区,就是刚刚 df -T /home,home目录所在的分区地址,参数--restore-all 是恢复所有最近删除的文件&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;完成后,即可在当前目录下产生一个 RECOVERED_FILES文件夹,里面放着这个分区近期删除的文件,至此恢复完成.&lt;/p&gt;

&lt;p&gt;参考博客&lt;a href=&quot;http://nphard.me/2015/09/30/linux-ubuntu-rm-hui-fu/&quot;&gt;http://nphard.me/2015/09/30/linux-ubuntu-rm-hui-fu/&lt;/a&gt;&lt;/p&gt;</content><author><name>liushan</name></author><summary type="html">Linux(Ubuntu)修复删除的文件</summary></entry><entry><title type="html">docker学习笔记(二)Dockerfile</title><link href="http://localhost:4000/2017/07/13/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C-Dockerfile/" rel="alternate" type="text/html" title="docker学习笔记(二)Dockerfile" /><published>2017-07-13T00:00:00+08:00</published><updated>2017-07-13T00:00:00+08:00</updated><id>http://localhost:4000/2017/07/13/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C--Dockerfile</id><content type="html" xml:base="http://localhost:4000/2017/07/13/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C-Dockerfile/">&lt;h2 id=&quot;docker学习笔记二dockerfile&quot;&gt;docker学习笔记二–Dockerfile&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;参考自&lt;a href=&quot;https://docs.docker.com/engine/reference/builder/#usage&quot;&gt;官方文档-Dockerfile&lt;/a&gt;部分&lt;/p&gt;

&lt;h3 id=&quot;一dockerfile中常用的指令简介&quot;&gt;(一)Dockerfile中常用的指令简介&lt;/h3&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM &lt;span class=&quot;c&quot;&gt;#来源于某个基础镜像&lt;/span&gt;
FROM ubuntu 16.04


LABEL
ARG SPRING_PROFILE_ACTIVE &lt;span class=&quot;c&quot;&gt;#获取外部参数 SPRING_PROFILE_ACTIVE为外部参数的名称&lt;/span&gt;
RUN  &lt;span class=&quot;c&quot;&gt;#运行镜像中系统级的命令&lt;/span&gt;
RUN apt-get uppdate &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y 

RUN apt-get update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    aufs-tools &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    automake &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    build-essential &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    curl &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    dpkg-sig &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    libcap-dev &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    libsqlite3-dev &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    mercurial &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    reprepro &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    ruby1.9.1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    ruby1.9.1-dev &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;s3cmd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.1.&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm -rf /var/lib/apt/lists/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;

RUN &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/bin/bash&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;-c&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;set -o pipefail &amp;amp;&amp;amp; wget -O - https://some.site | wc -l &amp;gt; /number&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

CMD  &lt;span class=&quot;c&quot;&gt;#运行非系统级别的命令&lt;/span&gt;
CMD &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;perl&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;-de0&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
ENV  &lt;span class=&quot;c&quot;&gt;#设置系统参数&lt;/span&gt;
ADD or COPY 

COPY /home/userName/xxx.jar  /images/  &lt;span class=&quot;c&quot;&gt;#讲系统中的内容copy到镜像中的指定目录&lt;/span&gt;
ENV profile &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPRING_PROFILE_ACTIVE&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#设置参数  ${SPRING_PROFILE_ACTIVE}为外部传入参数&lt;/span&gt;
CMD &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bash,-c,java -jar /xxx.jar --spring.profiles.active&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;profile&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;/home/userName/xxx.jar为当前系统目录下的内容&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 目标地址为镜像目录 /images/
 
EXPOSE  &lt;span class=&quot;c&quot;&gt;# 不常用,后续补充该字段&lt;/span&gt;
ENTRYPOINT
VOLUME
USER
WORKDIR
ONBUILD

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;二一些简单的dockerfile示例&quot;&gt;(二)一些简单的Dockerfile示例&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;以下为一个简介版本的Dockerfile
``` bash
FROM openjdk:8
ARG SPRING_PROFILE_ACTIVE&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ENV SPRING_PROFILE_ACTIVE ${SPRING_PROFILE_ACTIVE}&lt;/p&gt;

&lt;p&gt;COPY demo-www-1.0-SNAPSHOT.jar  /temp/&lt;/p&gt;

&lt;p&gt;CMD [bash,-c,java -jar   /temp/demo-www-1.0-SNAPSHOT.jar –spring.profiles.active=${SPRING_PROFILE_ACTIVE}]&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; 项目中使用的镜像
``` bash 
# 基于一个简介版本的可运行jdk环境的docker镜像
FROM reg.longdai.com/base/openjdk:8u131-jdk-alpine

# 作者信息
MAINTAINER mritd &amp;lt;mritd@mritd.me&amp;gt;

# 获取参数
ARG SPRING_PROFILE_ACTIVE
ARG PROJECT_BUILD_FINALNAME

# 设置时区,项目参数,项目名称
ENV TZ 'Asia/Shanghai'
ENV SPRING_PROFILE_ACTIVE ${SPRING_PROFILE_ACTIVE}
ENV PROJECT_BUILD_FINALNAME ${PROJECT_BUILD_FINALNAME}

# 运行命令设置和安装 搭建项目所需要环境
RUN apk upgrade --update \
    &amp;amp;&amp;amp; apk add tzdata bash \
    &amp;amp;&amp;amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;amp;&amp;amp; echo &quot;Asia/Shanghai&quot; &amp;gt; /etc/timezone \
    &amp;amp;&amp;amp; rm -rf /var/cache/apk/*

# copy 项目中可运行的jar包到镜像中
COPY target/${PROJECT_BUILD_FINALNAME}.jar /${PROJECT_BUILD_FINALNAME}.jar

# 执行启动命令,项目使用spring-boot框架搭建,所以直接使用此命令就好
CMD [&quot;bash&quot;,&quot;-c&quot;,&quot;java -jar /${PROJECT_BUILD_FINALNAME}.jar --spring.profiles.active=${SPRING_PROFILE_ACTIVE}&quot;]

# 更复杂的Dockerfile待更新
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;三build-dcokerfile&quot;&gt;(三)build Dcokerfile&lt;/h3&gt;
&lt;p&gt;写完Dockerfile后,使用docker build 命令build自己的镜像&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker build /path/to/a/Dockerfile  -t testDocker:1.2 .

docker -H https://githu.com/xxx/xxx.git  build -t image_name:1.12 --build-arg &lt;span class=&quot;nv&quot;&gt;SPRING_PROFILE_ACTIVE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;dohko   &lt;span class=&quot;nv&quot;&gt;PROJECT_BUILD_FINALNAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;longdai-p2p-core longdai-core

&lt;span class=&quot;c&quot;&gt;# 为镜像指定tag&lt;/span&gt;
docker -H &lt;span class=&quot;nv&quot;&gt;$DOHKO_BUILD_HOST_19&lt;/span&gt; tag &lt;span class=&quot;nv&quot;&gt;$IMAGE_NAME&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$LATEST_IMAGE_NAME&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 将镜像push到指定仓库&lt;/span&gt;
docker -H &lt;span class=&quot;nv&quot;&gt;$DOHKO_BUILD_HOST_19&lt;/span&gt; push &lt;span class=&quot;nv&quot;&gt;$IMAGE_NAME&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 删除本地的docker镜像&lt;/span&gt;
docker -H &lt;span class=&quot;nv&quot;&gt;$DOHKO_BUILD_HOST_19&lt;/span&gt;  rmi &lt;span class=&quot;nv&quot;&gt;$IMAGE_NAME&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 指定build的文件来源地址&lt;/span&gt;
-H https://githu.com/xxx/xxx.git 
&lt;span class=&quot;c&quot;&gt;# build后的镜像名称为: image_name:1.12 &lt;/span&gt;
build -t image_name:1.12 
&lt;span class=&quot;c&quot;&gt;# build 时带入的参数&lt;/span&gt;
--build-arg &lt;span class=&quot;nv&quot;&gt;SPRING_PROFILE_ACTIVE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;dohko   &lt;span class=&quot;nv&quot;&gt;PROJECT_BUILD_FINALNAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;longdai-p2p-core
&lt;span class=&quot;c&quot;&gt;# build的文件中的目录&lt;/span&gt;
longdai-core



&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;更多详细的命令参考&lt;a href=&quot;https://docs.docker.com/engine/reference/builder/&quot;&gt;官方文档Dockerfile reference&lt;/a&gt;&lt;/p&gt;</content><author><name>liushan</name></author><summary type="html">docker学习笔记二–Dockerfile 参考自官方文档-Dockerfile部分</summary></entry></feed>