<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="http://jekyllrb.com" version="3.4.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-04-16T15:22:38+08:00</updated><id>http://localhost:4000/</id><title type="html">code busy</title><subtitle>code busy的个人博客</subtitle><author><name>liushan</name></author><entry><title type="html">hadoop-HA(高可用)集群搭建</title><link href="http://localhost:4000/2018/04/16/hadoop-HA(%E9%AB%98%E5%8F%AF%E7%94%A8)%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/" rel="alternate" type="text/html" title="hadoop-HA(高可用)集群搭建" /><published>2018-04-16T00:00:00+08:00</published><updated>2018-04-16T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/16/hadoop-HA(%E9%AB%98%E5%8F%AF%E7%94%A8)%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA</id><content type="html" xml:base="http://localhost:4000/2018/04/16/hadoop-HA(%E9%AB%98%E5%8F%AF%E7%94%A8)%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">&lt;h4 id=&quot;准备工作&quot;&gt;准备工作&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;静态IP&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;映射主机名与ip&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;jdk环境&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;防火墙关闭&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;ssh免密&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;高可用原理介绍&quot;&gt;高可用原理介绍&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;为何使用ha&quot;&gt;为何使用HA&lt;br /&gt;&lt;/h5&gt;
    &lt;p&gt;因为在非HA集群模式下namenode是单节点工作,故存在namenode的单节点故障.&lt;br /&gt;
为防止故障发生,需要使用多个namenode节点.&lt;br /&gt;
其中,hadoop2.x版本只能支持2个namenode节点 ,hadoop3.x可以支持更多个&lt;br /&gt;
本文以hadoop2.7.2版本为基础
&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;ha实现原理&quot;&gt;HA实现原理&lt;/h5&gt;
    &lt;p&gt;两个namenode的数据是一致的.&lt;br /&gt;
两个namenode通过hadoop中的journalnode集群服务来同步两个namenode的元数据&lt;br /&gt;
两个namenode工作时,其中一台处于active状态,另外一台处于standy状态,否则会出现(split-brain)脑裂,集群无法工作.&lt;br /&gt;
在故障自动转移中, 通过 zookeeper 中的ZKFC(zookeeper failover controller,zookeeper 故障转移控制)进程来控制namenode节点的工作状态切换&lt;br /&gt;
其中ZKFC会在两个namenode节点只监听namenode的状态信息,不会对元数据进行操作,&lt;br /&gt;
当处于active的namenode宕机或死掉,zookeeper会通过ZKFC通知另外一台namenode启用(active)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;namenode的高可用配置&quot;&gt;namenode的高可用配置&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;1解压或复制原来hadoop集群相关文件&quot;&gt;1.解压或复制原来hadoop集群相关文件&lt;br /&gt;&lt;/h5&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  tar -zxf hadoop-2.7.2.tar.gz -C ~/module/HA/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;2配置hadoop相关文件&quot;&gt;2.配置hadoop相关文件&lt;/h5&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  cd /home/admin/module/HA/hadoop-2.7.2/etc/hadoop    
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑core-sitexml此时为非自动故障转移&quot;&gt;编辑core-site.xml(此时为非自动故障转移)&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;configuration&amp;gt;
    &amp;lt;!-- 把两个NameNode）的地址组装成一个集群haCluster(haCluster为集群名称,后续需要跟此保持一致) --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hdfs://haCluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- # dfs 系统存取数据的目录 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/admin/module/HA/hadoop-2.7.2/data/tmp&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- journalnode 数据存储目录 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.journalnode.edit.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/home/admin/module/HA/hadoop-2.7.2/jn/haCluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- zookeeper通信客户端地址  --&amp;gt;
    &amp;lt;!-- &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;ha.zookeeper.quorum&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hd001:2181,hd002:2181,hd003:2181&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;  --&amp;gt;

  &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑hdfs-sitexml&quot;&gt;编辑hdfs-site.xml&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;configuration&amp;gt;
    &amp;lt;!-- 完全分布式集群名称 haCluster 此处的haCluster与core-site.xmlvs中的集群名称需要一致,此xml种的haCluster都是集群对应的名称 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.nameservices&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;haCluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 集群中NameNode节点都有哪些 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.namenodes.haCluster&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;nn1,nn2&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- nn1的RPC通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.rpc-address.haCluster.nn1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd002:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

     &amp;lt;!-- nn2的RPC通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.rpc-address.haCluster.nn2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd003:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- nn1的http通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.http-address.haCluster.nn1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd002:50070&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- nn2的http通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.http-address.haCluster.nn2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd003:50070&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.shared.edits.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;qjournal://hd001:8485;hd002:8485;hd003:8485/haCluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
   &amp;lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.fencing.methods&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;sshfence&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 使用隔离机制时需要ssh无秘钥登录--&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.private-key-files&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/home/admin/.ssh/id_rsa&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 声明journalnode服务器存储目录--&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.journalnode.edits.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/home/admin/module/HA/hadoop-2.7.2/jn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 关闭权限检查--&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.permissions.enable&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.client.failover.proxy.provider.haCluster&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- # hdfs文件系统中的文件副本数量 为1(一般情况,完全分布式都是3分以上基数份) --&amp;gt;
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- # hdfs文件系统中的文件副本数量 为1(一般情况,完全分布式都是3分以上基数份) --&amp;gt;
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;!-- # 节点检测频率,用户namenode 检测datanode是否存活 120s --&amp;gt;
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.namenode.checkpoint.period&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;120&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- 启用web查看hdfs系统 --&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.webhdfs.enabled&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- 启用自动故障转移 --&amp;gt;
    &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- # 指定 dfs 相关的机器地址,用户上下线新的机器 --&amp;gt;
    &amp;lt;!-- &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.hosts&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    # 指定退役的节点
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;dfs.hosts.exclude&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt; --&amp;gt;
  &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑mapred-sitexml&quot;&gt;编辑mapred-site.xml&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;configuration&amp;gt;
      &amp;lt;!-- 指定mr运行在yarn上 --&amp;gt;
        &amp;lt;property&amp;gt;
                &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
                &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
        &amp;lt;/property&amp;gt;

        &amp;lt;!--配置历史服务器 --&amp;gt;
        &amp;lt;property&amp;gt;
                &amp;lt;name&amp;gt;mapreduce.jobhistory.address&amp;lt;/name&amp;gt;
                &amp;lt;value&amp;gt;hd001:10020&amp;lt;/value&amp;gt;
        &amp;lt;/property&amp;gt;
        &amp;lt;property&amp;gt;
                &amp;lt;name&amp;gt;mapreduce.jobhistory.webapp.address&amp;lt;/name&amp;gt;
                &amp;lt;value&amp;gt;hd001:19888&amp;lt;/value&amp;gt;
        &amp;lt;/property&amp;gt;

  &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;将hadoop目录分发至集群每台机器&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  scp -r /home/admin/module/HA/hadoop-2.7.2 hd002:~/module/HA/
  scp -r /home/admin/module/HA/hadoop-2.7.2 hd003:~/module/HA/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;至此 namenode高可用搭建完成,但是不是自动故障转移,切换namenode的active状态需要手动&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑yarn-sitexml此处为非自动故障转移的配置&quot;&gt;编辑yarn-site.xml(此处为非自动故障转移的配置)&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &amp;lt;!-- 指定YARN的ResourceManager的地址 --&amp;gt;
    &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;hd002&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
      &amp;lt;!-- 日志聚集功能使能 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
      &amp;lt;!-- 日志保留时间设置7天 7*24*60*60 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log-aggregation.retain-seconds&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;604800&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!-- 日志储存地址 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log.server.url&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;http://hd001:19888/jobhistory/logs&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h6 id=&quot;编辑-slaves&quot;&gt;编辑 slaves&lt;/h6&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  hd001
  hd002
  hd003
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;namenode高可用测试&quot;&gt;namenode高可用测试&lt;/h5&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;首先启动集群journalnode集群服务&quot;&gt;首先启动集群journalnode集群服务&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  #需要启动每个节点的 journalnode 
  $ cd /home/admin/module/HA/hadoop-2.7.2
  $ sbin/hadoop-daemon.sh start journalnode
  $ jps
      7684 Jps
      7609 JournalNode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;格式化namenode&quot;&gt;格式化namenode&lt;/h6&gt;
        &lt;font color=&quot;red&quot;&gt;注意: 为了使journalnode服务记录namenode初始信息,在格式化namenode前,需要先将journalnode集群服务启动,否则会失败&lt;/font&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  $ bin/hdfs namenode -format
  #  Storage directory /home/admin/module/HA/hadoop-2.7.2/data/tmp/dfs/name has been successfully formatted.
  #  出现这句话时,表示format成功
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;启动nn1的namenode&quot;&gt;启动nn1的namenode&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  sbin/hadoop-daemon.sh start namenode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;nn2同步nn1-的元数据信息&quot;&gt;nn2同步nn1 的元数据信息&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  bin/hdfs namenode -bootstrapStandby

&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;启动nn2的namenode&quot;&gt;启动nn2的namenode&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  sbin/hadoop-daemon.sh start namenode

&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;启动各个节点的datanode&quot;&gt;启动各个节点的datanode&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  # 每隔节点都需要启动 hd001 hd002 hd003
  $ sbin/hadoop-daemon.sh start datanode 

  $ sh ~/jpsutil.sh
  =========== admin@hd001 ============
  11010 DataNode
  11400 Jps
  10286 JournalNode
  =========== admin@hd002 ============
  9744 Jps
  9473 DataNode
  9317 NameNode
  8959 JournalNode
  =========== admin@hd003 ============
  8881 DataNode
  8388 JournalNode
  9161 Jps
  8746 NameNode

  #hd002,hd003中的namenode启动成功
  # 此时 访问 http://hd002:50070/  和 http://hd003:50070/  均发现两个节点处于 standy状态
  # 访问http://hd002:50070/explorer.html#/ 文件目录会提示时: 
  Operation category READ is not supported in state standby
  因为没有active的name造成的

&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;手动激活nn1中的namenode到active&quot;&gt;手动激活nn1中的namenode到active&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  bin/hdfs haadmin -transitionToActive nn1
  #此时再访问 http://hd002:50070/dfshealth.html#tab-overview 显示节点处于active
  访问 http://hd002:50070/explorer.html#/ 可以正常访问
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;手动激活nn2中的namenode到active&quot;&gt;手动激活nn2中的namenode到active&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  bin/hdfs haadmin -transitionToActive nn2
  Automatic failover is enabled for NameNode at hd002/192.168.1.21:9000
  Refusing to manually manage HA state, since it may cause
  a split-brain scenario or other incorrect state.
  If you are very sure you know what you are doing, please
  specify the --forcemanual flag.

  如果使用
  bin/hdfs haadmin -transitionToActive nn2  --forcemanual
  会提示 nn1已经处于active 不会被切换,切换失败
  18/04/16 18:56:57 WARN ha.HAAdmin: Proceeding with manual HA state management even though
  automatic failover is enabled for NameNode at hd002/192.168.1.21:9000
  transitionToActive: Node nn1 is already active
  Usage: haadmin [-transitionToActive [--forceactive] &amp;lt;serviceId&amp;gt;]
    
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;h6 id=&quot;手动激活nn1中的namenode到standby&quot;&gt;手动激活nn1中的namenode到standby&lt;/h6&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  bin/dfs haadmin -transitionToStandby nn1
  # 切换完后后,再切换nn2到active可成功切换
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ha的自动故障转移&quot;&gt;HA的自动故障转移&lt;/h4&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    以上测试了手动故障转移的方式,下面配置自动故障转移&amp;lt;br&amp;gt;
    HA的自动故障转移依赖于zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;配置zookeeper&quot;&gt;配置zookeeper&lt;/h5&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  tar -zxvf zookeeper-3.4.10.tar.gz ~/module/HA/
  cd ~/module/HA/zookeeper-3.4.10/
  mkdir zkData
  cd zkData
  echo 1 &amp;gt; myid
  cd ../conf/
  mv zoo_simple.cfg zoo.cfg
  vim zoo.cfg
  # 修改dataDir 
  dataDir=/home/admin/module/HA/zookeeper-3.4.10/zkData
  #末尾增加
  server.1=hd001:2888:3888
  server.2=hd002:2888:3888
  server.3=hd003:2888:3888

  #保存退出
  #将 zookeeper分发到各个节点,修改zkData下myid文件中的值,于主机名称对应
  scp -r ~/module/HA/zookeeper-3.4.10  hd002:~/module/HA/
  scp -r ~/module/HA/zookeeper-3.4.10  hd003:~/module/HA/

&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;至此,zookeeper配置完成&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;zookeeper启动测试&quot;&gt;zookeeper启动测试&lt;/h5&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  #每台节点启动zookeeper服务
  cd /home/admin/module/HA/zookeeper-3.4.10/
  bin/zkServer.sh start
  #查看进程
  [admin@hd001 zookeeper-3.4.10]$ sh ~/jpsutil.sh
  =========== admin@hd001 ============
  14452 Jps
  14390 QuorumPeerMain
  13033 DataNode
  10286 JournalNode
  =========== admin@hd002 ============
  11785 DataNode
  13291 Jps
  11164 NameNode
  13230 QuorumPeerMain
  8959 JournalNode
  =========== admin@hd003 ============
  12817 QuorumPeerMain
  8388 JournalNode
  10892 NameNode
  12879 Jps
  #在其中一台启动zkCli.sh连接服务
  ls /

&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;hdfs-sitexml增加配置&quot;&gt;hdfs-site.xml增加配置&lt;/h5&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;core-site增加配置&quot;&gt;core-site增加配置&lt;/h5&gt;
    &lt;p&gt;在 core-site.xml 增加&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      &amp;lt;!-- zookeeper通信客户端地址  --&amp;gt;
      &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;ha.zookeeper.quorum&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hd001:2181,hd002:2181,hd003:2181&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;故障自动转移完成&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;故障自动转移测试&quot;&gt;故障自动转移测试&lt;/h5&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  - 先停掉节点&amp;lt;br&amp;gt;
  sbin/stop-dfs.sh 

  - 初始化HA在Zookeeper中状态：&amp;lt;br&amp;gt;
  bin/hdfs zkfc -formatZK

  - 启动journalnode&amp;lt;br&amp;gt;
  sbin/hadoop-daemon.sh start journalnode

  - 启动dfs&amp;lt;br&amp;gt;
  sbin/start-dfs.sh &amp;lt;br&amp;gt;
  查看hd002:50070和hd003:50070,其中一台处于active
    
  - kill active namenode &amp;lt;br&amp;gt;
  sbin/hadoop-daemon.sh stop namenode &amp;lt;br&amp;gt;
  查看hd002:50070和hd003:50070,刚刚处于standby的namoenode自动切换为active了.
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;配置yarn-resourcemanager高可用&quot;&gt;配置yarn-resourcemanager高可用&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;编辑yarn-site.xml
    &lt;blockquote&gt;
      &lt;p&gt;可参考 &lt;a href=&quot;http://hadoop.apache.org/docs/r2.7.5/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html&quot; target=&quot;_blank&quot;&gt;Resourcemanager-HA官方文档&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;configuration&amp;gt;
      &amp;lt;!-- reducer获取数据的方式 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--启用resourcemanager ha--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.ha.enabled&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--声明两台resourcemanager的地址--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.cluster-id&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;cluster-yarn1&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.ha.rm-ids&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;rm1,rm2&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm1&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;hd001&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm2&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;hd002&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--指定zookeeper集群的地址--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.zk-address&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;hd001:2181,hd001:2181,hd001:2181&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--启用自动恢复--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.recovery.enabled&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&amp;gt;
      &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;yarn.resourcemanager.store.class&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
      &amp;lt;!-- 日志聚集功能使能 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
      &amp;lt;!-- 日志保留时间设置7天 --&amp;gt;
      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log-aggregation.retain-seconds&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;604800&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;

      &amp;lt;property&amp;gt;
              &amp;lt;name&amp;gt;yarn.log.server.url&amp;lt;/name&amp;gt;
              &amp;lt;value&amp;gt;http://hd001:19888/jobhistory/logs&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
  &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;配置完成,分发文件&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;rm1启动yarn集群
  sbin/start-yarn.sh&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;rm2启动resourcemanager
  sbin/yarn-daemon.sh start resourcemanager &lt;br /&gt;
      &lt;font color=&quot;red&quot;&gt;注意:&lt;br /&gt;
          1.rm2的resourcemanager不会同yarn集群一起启动,需要单独启动;&lt;br /&gt;
          2.yarn的resourcemanager的HA,不会经过ZKFC控制,是通过yarn集群自己进行自动切换的&lt;/font&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;查看集群进程
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  sh ~/jpsutil.sh
  [admin@hd001 hadoop-2.7.2]$ sh ~/jpsutil.sh
  =========== admin@hd001 ============
  27937 ResourceManager
  24390 QuorumPeerMain
  27160 JournalNode
  27513 NodeManager
  28026 Jps
  26894 DataNode
  =========== admin@hd002 ============
  27505 ResourceManager
  27271 DFSZKFailoverController
  28232 Jps
  27659 NodeManager
  22556 QuorumPeerMain
  27116 JournalNode
  26988 DataNode
  26861 NameNode
  =========== admin@hd003 ============
  25202 JournalNode
  25074 DataNode
  24968 NameNode
  25595 NodeManager
  22092 QuorumPeerMain
  26044 Jps
  25357 DFSZKFailoverController
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;可访问 rm1 和 rm2, hd002:8088  hd003:8088&lt;br /&gt;
本文中 rm2 hd002处于activ中, 当访问hd001:8088时,会自动重定向到 hd002:8088/cluster&lt;br /&gt;
当将 rm2 停止 后,rm1处于active中&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;附件-jpsutilsh&quot;&gt;附件 jpsutil.sh&lt;/h4&gt;
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      &lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;i &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;admin@hd001 admin@hd002 admin@hd003
      &lt;span class=&quot;k&quot;&gt;do
              &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;=========== &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; ============&quot;&lt;/span&gt;
              ssh &lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'jps'&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;hadoop-ha官方文档地址&quot;&gt;hadoop-HA&lt;a href=&quot;http://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html&quot; target=&quot;_blank&quot;&gt;官方文档地址&lt;/a&gt;&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>liushan</name></author><summary type="html">准备工作 静态IP 映射主机名与ip jdk环境 防火墙关闭 ssh免密</summary></entry><entry><title type="html">zookeeper集群相关问题</title><link href="http://localhost:4000/2018/04/13/zookeeper%E9%9B%86%E7%BE%A4%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/" rel="alternate" type="text/html" title="zookeeper集群相关问题" /><published>2018-04-13T00:00:00+08:00</published><updated>2018-04-13T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/13/zookeeper%E9%9B%86%E7%BE%A4%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98</id><content type="html" xml:base="http://localhost:4000/2018/04/13/zookeeper%E9%9B%86%E7%BE%A4%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">&lt;h3 id=&quot;问题一&quot;&gt;问题一&lt;/h3&gt;
&lt;h5 id=&quot;问题描述&quot;&gt;问题描述&lt;/h5&gt;
&lt;p&gt;第N次启动zookeeper集群时,按照节点顺序启动时,无法正常启动&lt;/p&gt;

&lt;h5 id=&quot;解决方案&quot;&gt;解决方案&lt;/h5&gt;
&lt;p&gt;需要先启动上次的leader节点.再一次启动其他节点,可以正常启动&lt;/p&gt;

&lt;h3 id=&quot;发现的问题&quot;&gt;发现的问题&lt;/h3&gt;
&lt;p&gt;第一次启动集群时,无需关注启动节点的顺序.第N(N&amp;gt;1)次启动时,需要先启动上次的leader节点,后启动其他节点,才能启动集群&lt;/p&gt;</content><author><name>liushan</name></author><summary type="html">问题一 问题描述 第N次启动zookeeper集群时,按照节点顺序启动时,无法正常启动</summary></entry><entry><title type="html">zookeeper集群搭建</title><link href="http://localhost:4000/2018/04/13/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/" rel="alternate" type="text/html" title="zookeeper集群搭建" /><published>2018-04-13T00:00:00+08:00</published><updated>2018-04-13T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/13/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA</id><content type="html" xml:base="http://localhost:4000/2018/04/13/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/">&lt;h2 id=&quot;准备工作&quot;&gt;准备工作&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;jdk环境&lt;/li&gt;
  &lt;li&gt;zookeeper安装包(本文使用的是zookeeper-3.4.10 版本) 可到&lt;a href=&quot;http://zookeeper.apache.org/releases.html&quot; target=&quot;_blank&quot;&gt;Zookeeper官网&lt;/a&gt;下载&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;步骤&quot;&gt;步骤&lt;/h2&gt;
&lt;h4 id=&quot;1解压文件&quot;&gt;1.解压文件&lt;/h4&gt;
&lt;p&gt;解压目标路径 /home/admin/module&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tar -zxvf zookeeper-3.4.10.tar.gz -C /home/admin/module/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;2修改配置&quot;&gt;2.修改配置&lt;/h4&gt;
&lt;p&gt;进入到zookeeper-3.4.10目录修改相关位置&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home/admin/module/zookeeper-3.4.10
mkdir zkData
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;conf
mv zoo_sample.cfg zoo.cfg
vim zoo.cfg
&lt;span class=&quot;nv&quot;&gt;dataDir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/admin/module/zookeeper-3.4.10/zkData
保存退出

&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ../zkData
&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;2 &amp;gt; myid
&lt;span class=&quot;c&quot;&gt;## 最后一行下面增加&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## 配置集群服务地址&lt;/span&gt;
server.2&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hd001:2888:3888
server.3&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hd002:2888:3888
server.4&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hd003:2888:3888

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h5 id=&quot;配置参数解读&quot;&gt;配置参数解读&lt;/h5&gt;
&lt;p&gt;Server.A=B:C:D。 &lt;br /&gt;
A是一个数字，表示这个是第几号服务器； &lt;br /&gt;
B是这个服务器的ip地址； &lt;br /&gt;
C是这个服务器与集群中的Leader服务器交换信息的端口； &lt;br /&gt;
D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的 &lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3分发文件&quot;&gt;3.分发文件&lt;/h4&gt;
&lt;p&gt;完成以上配置后,将此目录分发到其他机器节点&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rsync -rvl /home/admin/module/zookeeper-3.4.10 hd002:~/module/
rsync -rvl /home/admin/module/zookeeper-3.4.10 hd003:~/module/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;font color=&quot;red&quot;&gt;分发完成后修改对应文件 zookeeper-3.4.10/zkData/myid 中对应的值 ,&lt;br /&gt;
其中 myid 文件中的值与 server.3=hd002:2888:3888,server.3中的3对应
&lt;/font&gt;

&lt;h5 id=&quot;-注意&quot;&gt;&lt;font color=&quot;red&quot;&gt; 注意&lt;/font&gt;&lt;/h5&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1]scp -r /home/admin/module/zookeeper-3.4.10 hd002:~/module/
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;2]scp -r /home/admin/module/zookeeper-3.4.10/ hd002:~/module/
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;1],[2]效果一样

&amp;lt;1&amp;gt;/rsync -rvl /home/admin/module/zookeeper-3.4.10 hd002:~/module/
&amp;lt;2&amp;gt;rsync -rvl /home/admin/module/zookeeper-3.4.10/ hd002:~/module/
&lt;span class=&quot;gp&quot;&gt;&amp;lt;1&amp;gt;&amp;lt;2&amp;gt; &lt;/span&gt;是不同的
&amp;lt;1&amp;gt;中是将整个目录和目录下所有文件分发给hd002,会在hd002:~/module/下创建一个新的zookeeper-3.4.10目录并将文件同步过去
&amp;lt;2&amp;gt;是将整个目录下所有文件分发给hd001,不会将目录本身分发出去

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;4启动和查看命令&quot;&gt;4.启动和查看命令&lt;/h4&gt;
&lt;p&gt;需要分别到每台服务进行启动&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# hd001&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home/admin/module/zookeeper-3.4.10
bin/zkServer.sh start
bin/zkServer.sh status
&lt;span class=&quot;c&quot;&gt;#状态结果&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;admin@hd001 zookeeper-3.4.10]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /home/admin/module/zookeeper-3.4.10/bin/../conf/zoo.cfg
Mode: follower

&lt;span class=&quot;c&quot;&gt;# hd002&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home/admin/module/zookeeper-3.4.10
bin/zkServer.sh start
bin/zkServer.sh status
&lt;span class=&quot;c&quot;&gt;#状态结果(因本地已经重启过很多次 .此台机器第一次按顺序启动将会被选举为 leader的)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;admin@hd002 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./module/zookeeper-3.4.10/bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /home/admin/module/zookeeper-3.4.10/bin/../conf/zoo.cfg
Mode: follower
&lt;span class=&quot;c&quot;&gt;# hd003&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home/admin/module/zookeeper-3.4.10
bin/zkServer.sh start
bin/zkServer.sh status
&lt;span class=&quot;c&quot;&gt;#状态结果&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;admin@hd003 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./module/zookeeper-3.4.10/bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /home/admin/module/zookeeper-3.4.10/bin/../conf/zoo.cfg
Mode: leader
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;</content><author><name>liushan</name></author><summary type="html">准备工作 jdk环境 zookeeper安装包(本文使用的是zookeeper-3.4.10 版本) 可到Zookeeper官网下载</summary></entry><entry><title type="html">macos装虚拟机NAT网络互ping问题</title><link href="http://localhost:4000/2018/04/12/macos%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BANAT%E7%BD%91%E7%BB%9C%E4%BA%92ping%E9%97%AE%E9%A2%98/" rel="alternate" type="text/html" title="macos装虚拟机NAT网络互ping问题" /><published>2018-04-12T00:00:00+08:00</published><updated>2018-04-12T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/12/macos%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BANAT%E7%BD%91%E7%BB%9C%E4%BA%92ping%E9%97%AE%E9%A2%98</id><content type="html" xml:base="http://localhost:4000/2018/04/12/macos%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BANAT%E7%BD%91%E7%BB%9C%E4%BA%92ping%E9%97%AE%E9%A2%98/">&lt;h3 id=&quot;问题描述&quot;&gt;问题描述&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;macOS系统装虚拟机,虚拟机与宿主机互ping不通&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;解决方案&quot;&gt;解决方案&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;修改宿主机的VMware网络设置&lt;/li&gt;
  &lt;li&gt;编辑文件目录
    &lt;blockquote&gt;
      &lt;p&gt;/Library/Preferences/VMware Fusion/networking
内容如下&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1,0
&lt;span class=&quot;c&quot;&gt;# 此处禁用DHCP模式&lt;/span&gt;
answer VNET_1_DHCP no
answer VNET_1_DHCP_CFG_HASH A1C3DC05C0F343C380B049B0A45A95DD63494961
answer VNET_1_HOSTONLY_NETMASK 255.255.255.0
answer VNET_1_HOSTONLY_SUBNET 192.168.181.0
&lt;span class=&quot;c&quot;&gt;# 宿主机的ip地址&lt;/span&gt;
answer VNET_1_VIRTUAL_ADAPTER yes
answer VNET_1_VIRTUAL_ADAPTER_ADDR 10.10.1.67
&lt;span class=&quot;c&quot;&gt;# 禁用DHCP模式&lt;/span&gt;
answer VNET_8_DHCP no
answer VNET_8_DHCP_CFG_HASH 5197E3A254D370D2E0B1CCD8B3F59319D3A67453
&lt;span class=&quot;c&quot;&gt;# 子网掩码&lt;/span&gt;
answer VNET_8_HOSTONLY_NETMASK 255.255.255.0
&lt;span class=&quot;c&quot;&gt;# 子网网段 192.168.1.0-192.168.255.0&lt;/span&gt;
answer VNET_8_HOSTONLY_SUBNET 192.168.1.0
answer VNET_8_NAT yes
answer VNET_8_VIRTUAL_ADAPTER yes
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>liushan</name></author><summary type="html">问题描述 macOS系统装虚拟机,虚拟机与宿主机互ping不通</summary></entry><entry><title type="html">hadoop完全分布式环境搭建</title><link href="http://localhost:4000/2018/04/09/hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F)%E4%B8%80/" rel="alternate" type="text/html" title="hadoop完全分布式环境搭建" /><published>2018-04-09T00:00:00+08:00</published><updated>2018-04-09T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/09/hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F)%E4%B8%80</id><content type="html" xml:base="http://localhost:4000/2018/04/09/hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F)%E4%B8%80/">&lt;h2 id=&quot;准备工作&quot;&gt;准备工作:&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;三台或三台以上机器(本文以三台虚拟机为例)
    &lt;blockquote&gt;

      &lt;p&gt;centOS 6.8&lt;/p&gt;

      &lt;p&gt;VMware Fusion 10.1(maxos的虚拟机版本),window下推荐VMware 12或14稳定版&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;每台机器安装jdk,hadoop,并配置相应的环境变量
    &lt;blockquote&gt;

      &lt;p&gt;jdk 1.8&lt;/p&gt;

      &lt;p&gt;hadoop 2.7.2&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;安装规划&quot;&gt;安装规划&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;系统中新建个非root用户, 并且 将此用户修改用户root权限&lt;/li&gt;
  &lt;li&gt;所需安装文件全部存于/opt/software目录中&lt;/li&gt;
  &lt;li&gt;所有软件安装到  /opt/module目录下&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改/opt目录的拥有者  chgroup hadoop hdaoop&lt;/p&gt;

    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;主机&lt;/td&gt;
          &lt;td&gt;hadoop101&lt;/td&gt;
          &lt;td&gt;hadoop102&lt;/td&gt;
          &lt;td&gt;hadoop103&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;角色&lt;/td&gt;
          &lt;td&gt;namenode&lt;/td&gt;
          &lt;td&gt;datanode&lt;/td&gt;
          &lt;td&gt;datanode&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;datanode&lt;/td&gt;
          &lt;td&gt;resourcemanager&lt;/td&gt;
          &lt;td&gt;nodemanager&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;nodemanager&lt;/td&gt;
          &lt;td&gt;nodemanager&lt;/td&gt;
          &lt;td&gt;secondaryNameNode&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;机器设置&quot;&gt;机器设置&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;配置三台机器的ip为静态ip,并能够互相ping通,且能ping通外网&lt;/li&gt;
  &lt;li&gt;以下已一台机器为例&lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;新建用户&quot;&gt;新建用户&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;新建nginx用户并增加到nginx工作组,-g后跟组名 组和用户名都为hadoop,也可更改为其他用户名
useradd -g hadoop hadoop  (后续文章都以hadoop用户登录系统做操作)&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1、建用户：
adduser 用户名                           //新建用户
passwd 用户名                           //给用户设置密码
2、建工作组
groupadd 组名                         //新建工作组
3、新建用户同时增加工作组
useradd -g nginx nginx               //新建nginx用户并增加到nginx工作组,-g后跟组名
注：：-g 所属组 -d 家目录 -s 所用的SHELL
4、给已有的用户增加工作组
usermod -G groupname username
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;设置静态ip&quot;&gt;设置静态ip&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim /etc/sysconfig/network-scripts/ifcfg-eth0&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nv&quot;&gt;DEVICE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;eth0
  &lt;span class=&quot;nv&quot;&gt;TYPE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Ethernet
  &lt;span class=&quot;nv&quot;&gt;UUID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;c4fcd4b8-9338-4489-bee5-6797d077a036
  &lt;span class=&quot;nv&quot;&gt;NM_CONTROLLED&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
  &lt;span class=&quot;c&quot;&gt;# 设置静态ip地址&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;IPADDR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;192.168.1.102
  &lt;span class=&quot;c&quot;&gt;# 网关&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;GATEWAY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;192.168.1.2
  &lt;span class=&quot;nv&quot;&gt;NETMASK&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;255.255.255.0
  &lt;span class=&quot;c&quot;&gt;# 系统启动时启用&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;ONBOOT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
  &lt;span class=&quot;c&quot;&gt;# 设置为静态ip&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;BOOTPROTO&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;static
  &lt;span class=&quot;c&quot;&gt;# dns&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;DNS1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;114.114.114.114
  &lt;span class=&quot;nv&quot;&gt;PREFIX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;24
  &lt;span class=&quot;nv&quot;&gt;DEFROUTE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
  &lt;span class=&quot;nv&quot;&gt;IPV4_FAILURE_FATAL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
  &lt;span class=&quot;c&quot;&gt;# 禁用ipv6&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;IPV6INIT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;no
  &lt;span class=&quot;nv&quot;&gt;NAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;System eth0&quot;&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# mac地址 对应 /etc/udev/rules.d/70-persistent-net.rules 中的 ATTR{address}的值&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR{address}==&quot;00:0c:29:d8:7f:e3&quot;, ATTR{type}==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth0&quot;&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;HWADDR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;00:0c:29:d8:7f:e3
  &lt;span class=&quot;nv&quot;&gt;LAST_CONNECT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1520522957
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;修改hostname&quot;&gt;修改hostname&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim /etc/sysconfig/network&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;NETWORKING&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
&lt;span class=&quot;nv&quot;&gt;HOSTNAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hadoop102
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;重启&quot;&gt;重启&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;sudo reboot -h now&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo reboot -h now 
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;修改其他机器的静态ip和hostname&quot;&gt;修改其他机器的静态ip和hostname&lt;/h4&gt;
    &lt;p&gt;此处忽略,可以参考第一台的设置&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;安装jdk-和-hadoop&quot;&gt;安装jdk 和 hadoop&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;下载jdk 和 hadoop压缩包存于 /opt/software目录中&lt;/li&gt;
  &lt;li&gt;将jdk压缩包,hadoop压缩包解到  /opt/module
    &lt;blockquote&gt;
      &lt;p&gt;tar -zxvf&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 解压命令&lt;/span&gt;
tar -zxvf /opt/software/jdk-8u144-linux-x64.tar.gz -C /opt/module
tar -zxvf /opt/software/hadoop-2.7.2.tar.gz -C /opt/module
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;配置JAVA_HOME和PATH ,编辑/etc/profile文件,最后一行添加如下
    &lt;blockquote&gt;
      &lt;p&gt;sudo vim /etc/profile&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/opt/module/jdk1.8.0_144
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/opt/module/hadoop-2.7.2
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/bin
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/sbin
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;检验是否安装成功
    &lt;blockquote&gt;
      &lt;p&gt;java -version&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java version &lt;span class=&quot;s2&quot;&gt;&quot;1.8.0_144&quot;&lt;/span&gt;
Java&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;TM&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; SE Runtime Environment &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;build 1.8.0_144-b01&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Java HotSpot&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;TM&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 64-Bit Server VM &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;build 25.144-b01, mixed mode&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
      &lt;p&gt;hadoop version&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Hadoop 2.7.2
Subversion Unknown -r Unknown
Compiled by root on 2017-05-22T10:49Z
Compiled with protoc 2.5.0
From &lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;with checksum d0fda26633fa762bff87ec759ebe689c
This &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;was run using /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;配置-hadoop&quot;&gt;配置 hadoop&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;进入到 /opt/module/hadoop-2.7.2/etc/hadoop 目录下&lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;编辑hadoop-envsh&quot;&gt;编辑hadoop-env.sh&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim hadoop-env.sh 配置JAVA_HOME&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/opt/module/jdk1.8.0_144
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;编辑hdfs-sitexml&quot;&gt;编辑hdfs-site.xml&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim hdfs-site.xml&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
          # hdfs文件系统中的文件副本数量 为3(一般情况,完全分布式都是3分以上基数份)
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # 第二名称辅助节点地址和端口
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.secondary.http-address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop104:50090&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # 节点检测频率,用户namenode 检测datanode是否存活 120s
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.checkpoint.period&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;120&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # namenode存name相关数据地址
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/module/hadoop-2.7.2/data/tmp/dfs/name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

          #多namenode的name目录,其中 name1 和name2的数据不会重复
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:///${hadoop.tmp.dir}/dfs/name1,file:///${hadoop.tmp.dir}/dfs/name2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # 指定 dfs 相关的机器地址,用户上下线新的机器
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.hosts&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          # 指定退役的节点
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.hosts.exclude&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;编辑-core-sitexml&quot;&gt;编辑 core-site.xml&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim core-site.xml&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
      # dfs 的名称节点
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://hadoop102:9000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
      # dfs 系统存取数据的目录
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.trash.interval&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.http.staticuser.user&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;配置yarn-sitexml&quot;&gt;配置yarn-site.xml&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim yarn-site.xml&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- reducer获取数据的方式 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mapreduce_shuffle&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

          &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 指定YARN的ResourceManager的地址 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hd002&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 日志聚集功能使能 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.log-aggregation-enable&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 日志保留时间设置7天 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.log-aggregation.retain-seconds&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;604800&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;编辑maperd-sitexml&quot;&gt;编辑maperd-site.xml&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim maperd-site.xml&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 指定mr运行在yarn上 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.framework.name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;yarn&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

          &lt;span class=&quot;c&quot;&gt;&amp;lt;!--配置历史服务器 --&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.jobhistory.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop101:10020&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.jobhistory.webapp.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hadoop101:19888&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;配置集群地址&quot;&gt;配置集群地址&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;vim slaves&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hadoop102
hadoop103
hadoop104
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;分发文件&quot;&gt;分发文件&lt;/h4&gt;
  &lt;/li&gt;
  &lt;li&gt;将/opt/moudle/目录下所有文件分发到其他机器
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;c&quot;&gt;# 可自定义脚本执行&lt;/span&gt;
  rsync -rvl /opt/moudle hadoop@hadoop102:/opt/moudle
  rsync -rvl /opt/moudle hadoop@hadoop103:/opt/moudle
  rsync -rvl /opt/moudle hadoop@hadoop104:/opt/moudle
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;将/etc/profile文件分发到其他机器
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; rsync -rvl /etc/profile hadoop@hadoop102:/etc
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;启动查看结果&quot;&gt;启动查看结果&lt;/h4&gt;
    &lt;blockquote&gt;
      &lt;p&gt;hadoop101上 启动 dfs&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      sbin/start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;blockquote&gt;
      &lt;p&gt;hadoop102上 启动 yarn&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      sbin/start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;blockquote&gt;
      &lt;p&gt;查看结果&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  hadoop101&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jps
  36577 SecondaryNameNode
  38209 Jps
  35314 DataNode
  35604 NodeManager
  35160 NameNode

  hadoop102&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jps
  37283 NodeManager
  36981 ResourceManager
  36829 DataNode
  41519 Jps

  hadoop103&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jps
  36577 SecondaryNameNode
  36678 NodeManager
  36438 DataNode
  41403 Jps

&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;自定义脚本分发文件
    &lt;blockquote&gt;
      &lt;p&gt;新建自定义脚本文件 touch /usr/bin/xsync&lt;/p&gt;
      &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo chmod +x /usr/bin/xsync
vim /usr/bin/xsync
&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
    &lt;/blockquote&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# 获取输入参数个数&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;pcount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$#&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;pcount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;0&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;;&lt;span class=&quot;k&quot;&gt;then
 &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;no args;
 &lt;span class=&quot;nb&quot;&gt;exit&lt;/span&gt;;
 &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;

 &lt;span class=&quot;c&quot;&gt;# 获取文件名&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;fname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;basename &lt;span class=&quot;nv&quot;&gt;$p1&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
 &lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;fname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$fname&lt;/span&gt;

 &lt;span class=&quot;c&quot;&gt;# 获取上机目录到绝对路径&lt;/span&gt;

 &lt;span class=&quot;nv&quot;&gt;pdir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; -P &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;dirname &lt;span class=&quot;nv&quot;&gt;$p1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;; &lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;

 &lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;pdir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$pdir&lt;/span&gt;

 &lt;span class=&quot;c&quot;&gt;# 获取当前用户名&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;whoami&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;103;host&amp;lt;109;host++&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;;&lt;span class=&quot;k&quot;&gt;do
         &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; --------------------hadoop&lt;span class=&quot;nv&quot;&gt;$host&lt;/span&gt;-----------------
         rsync -rvl &lt;span class=&quot;nv&quot;&gt;$pdir&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$fname&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$user&lt;/span&gt;@hadoop&lt;span class=&quot;nv&quot;&gt;$host&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$pdir&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;done

 &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;success&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>liushan</name></author><summary type="html">准备工作: 三台或三台以上机器(本文以三台虚拟机为例) centOS 6.8 VMware Fusion 10.1(maxos的虚拟机版本),window下推荐VMware 12或14稳定版 每台机器安装jdk,hadoop,并配置相应的环境变量 jdk 1.8 hadoop 2.7.2</summary></entry><entry><title type="html">本地jekyll-server启动证书错误问题</title><link href="http://localhost:4000/2018/04/09/%E6%9C%AC%E5%9C%B0jekyll-server%E5%90%AF%E5%8A%A8%E8%AF%81%E4%B9%A6%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98/" rel="alternate" type="text/html" title="本地jekyll-server启动证书错误问题" /><published>2018-04-09T00:00:00+08:00</published><updated>2018-04-09T00:00:00+08:00</updated><id>http://localhost:4000/2018/04/09/%E6%9C%AC%E5%9C%B0jekyll-server%E5%90%AF%E5%8A%A8%E8%AF%81%E4%B9%A6%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98</id><content type="html" xml:base="http://localhost:4000/2018/04/09/%E6%9C%AC%E5%9C%B0jekyll-server%E5%90%AF%E5%8A%A8%E8%AF%81%E4%B9%A6%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98/">&lt;hr /&gt;

&lt;h3 id=&quot;问题描述&quot;&gt;问题描述:&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;本地启动jekyll server 博客时显示如下错误:&lt;/p&gt;
  &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Liquid Exception: SSL_connect &lt;span class=&quot;nv&quot;&gt;returned&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1 &lt;span class=&quot;nv&quot;&gt;errno&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &lt;span class=&quot;nv&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;error: certificate verify failed &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /_layouts/page.html
jekyll 3.6.2 | Error:  SSL_connect &lt;span class=&quot;nv&quot;&gt;returned&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1 &lt;span class=&quot;nv&quot;&gt;errno&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0 &lt;span class=&quot;nv&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;error: certificate verify failed    
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;解决方案&quot;&gt;解决方案:&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;1.下载一个证书 名称为: cacert.pem&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;2.将证书路径设置到系统变量中&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;window下 可使用命令 set SSL_CERT_FILE=d:/XmacZone/down/cacert.pem&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;linux 或macos 编制.brash 或.zshrc&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后一行添加 export  SSL_CERT_FILE=/Users/XmacZone/down/cacert.pem   ;执行命令 source ~/.zshrc 即可.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>liushan</name></author><summary type="html"></summary></entry><entry><title type="html">linux下恢复删除的文件</title><link href="http://localhost:4000/2017/07/18/linux%E4%B8%AD%E6%81%A2%E5%A4%8D%E5%88%A0%E9%99%A4%E7%9A%84%E6%96%87%E4%BB%B6/" rel="alternate" type="text/html" title="linux下恢复删除的文件" /><published>2017-07-18T00:00:00+08:00</published><updated>2017-07-18T00:00:00+08:00</updated><id>http://localhost:4000/2017/07/18/linux%E4%B8%AD%E6%81%A2%E5%A4%8D%E5%88%A0%E9%99%A4%E7%9A%84%E6%96%87%E4%BB%B6</id><content type="html" xml:base="http://localhost:4000/2017/07/18/linux%E4%B8%AD%E6%81%A2%E5%A4%8D%E5%88%A0%E9%99%A4%E7%9A%84%E6%96%87%E4%BB%B6/">&lt;h2 id=&quot;linuxubuntu修复删除的文件&quot;&gt;Linux(Ubuntu)修复删除的文件&lt;/h2&gt;

&lt;p&gt;本人基于Ubuntu server 16.04 环境下,其他linux系统类似.
作为一个初学者,难免有不小心删除文件的误操作,google了下,成功恢复了.&lt;/p&gt;

&lt;h3 id=&quot;查看自己的文件系统和分区&quot;&gt;查看自己的文件系统和分区&lt;/h3&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;hadoop@ubuntu-ser1:~/devapp$ &lt;/span&gt;df -T /home
Filesystem                        Type 1K-blocks    Used Available Use% Mounted on
/dev/mapper/ubuntu--ser1--vg-root ext4  18982780 3766336  14229104  21% /

&lt;span class=&quot;c&quot;&gt;## /dev/mapper/ubuntu--ser1--vg-root 就是当前系统所在分区  ext4是文件系统类型&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;安装恢复文件所需的软件extundelete&quot;&gt;安装恢复文件所需的软件extundelete&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt install extundelete -y

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;恢复文件&quot;&gt;恢复文件&lt;/h3&gt;
&lt;p&gt;跳转到一个目录,最好是不需要的目录,因为一会恢复的文件会恢复到这个目录;例如,我跳到了我刚刚删除文件的那个目录&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/devapp/

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后执行&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo extundelete /dev/mapper/ubuntu--ser1--vg-root --restore-all
&lt;span class=&quot;c&quot;&gt;## /dev/mapper/ubuntu--ser1--vg-root 这个是文件所在的分区,就是刚刚 df -T /home,home目录所在的分区地址,参数--restore-all 是恢复所有最近删除的文件&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;完成后,即可在当前目录下产生一个 RECOVERED_FILES文件夹,里面放着这个分区近期删除的文件,至此恢复完成.&lt;/p&gt;

&lt;p&gt;参考博客&lt;a href=&quot;http://nphard.me/2015/09/30/linux-ubuntu-rm-hui-fu/&quot;&gt;http://nphard.me/2015/09/30/linux-ubuntu-rm-hui-fu/&lt;/a&gt;&lt;/p&gt;</content><author><name>liushan</name></author><summary type="html">Linux(Ubuntu)修复删除的文件</summary></entry><entry><title type="html">docker学习笔记(二)Dockerfile</title><link href="http://localhost:4000/2017/07/13/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C-Dockerfile/" rel="alternate" type="text/html" title="docker学习笔记(二)Dockerfile" /><published>2017-07-13T00:00:00+08:00</published><updated>2017-07-13T00:00:00+08:00</updated><id>http://localhost:4000/2017/07/13/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C--Dockerfile</id><content type="html" xml:base="http://localhost:4000/2017/07/13/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C-Dockerfile/">&lt;h2 id=&quot;docker学习笔记二dockerfile&quot;&gt;docker学习笔记二–Dockerfile&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;参考自&lt;a href=&quot;https://docs.docker.com/engine/reference/builder/#usage&quot;&gt;官方文档-Dockerfile&lt;/a&gt;部分&lt;/p&gt;

&lt;h3 id=&quot;一dockerfile中常用的指令简介&quot;&gt;(一)Dockerfile中常用的指令简介&lt;/h3&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM &lt;span class=&quot;c&quot;&gt;#来源于某个基础镜像&lt;/span&gt;
FROM ubuntu 16.04


LABEL
ARG SPRING_PROFILE_ACTIVE &lt;span class=&quot;c&quot;&gt;#获取外部参数 SPRING_PROFILE_ACTIVE为外部参数的名称&lt;/span&gt;
RUN  &lt;span class=&quot;c&quot;&gt;#运行镜像中系统级的命令&lt;/span&gt;
RUN apt-get uppdate &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y 

RUN apt-get update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    aufs-tools &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    automake &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    build-essential &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    curl &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    dpkg-sig &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    libcap-dev &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    libsqlite3-dev &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    mercurial &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    reprepro &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    ruby1.9.1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    ruby1.9.1-dev &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;s3cmd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.1.&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; rm -rf /var/lib/apt/lists/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;

RUN &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/bin/bash&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;-c&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;set -o pipefail &amp;amp;&amp;amp; wget -O - https://some.site | wc -l &amp;gt; /number&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

CMD  &lt;span class=&quot;c&quot;&gt;#运行非系统级别的命令&lt;/span&gt;
CMD &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;perl&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;-de0&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
ENV  &lt;span class=&quot;c&quot;&gt;#设置系统参数&lt;/span&gt;
ADD or COPY 

COPY /home/userName/xxx.jar  /images/  &lt;span class=&quot;c&quot;&gt;#讲系统中的内容copy到镜像中的指定目录&lt;/span&gt;
ENV profile &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPRING_PROFILE_ACTIVE&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#设置参数  ${SPRING_PROFILE_ACTIVE}为外部传入参数&lt;/span&gt;
CMD &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bash,-c,java -jar /xxx.jar --spring.profiles.active&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;profile&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;/home/userName/xxx.jar为当前系统目录下的内容&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 目标地址为镜像目录 /images/
 
EXPOSE  &lt;span class=&quot;c&quot;&gt;# 不常用,后续补充该字段&lt;/span&gt;
ENTRYPOINT
VOLUME
USER
WORKDIR
ONBUILD

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h3 id=&quot;二一些简单的dockerfile示例&quot;&gt;(二)一些简单的Dockerfile示例&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;以下为一个简介版本的Dockerfile
``` bash
FROM openjdk:8
ARG SPRING_PROFILE_ACTIVE&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ENV SPRING_PROFILE_ACTIVE ${SPRING_PROFILE_ACTIVE}&lt;/p&gt;

&lt;p&gt;COPY demo-www-1.0-SNAPSHOT.jar  /temp/&lt;/p&gt;

&lt;p&gt;CMD [bash,-c,java -jar   /temp/demo-www-1.0-SNAPSHOT.jar –spring.profiles.active=${SPRING_PROFILE_ACTIVE}]&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; 项目中使用的镜像
``` bash 
# 基于一个简介版本的可运行jdk环境的docker镜像
FROM reg.longdai.com/base/openjdk:8u131-jdk-alpine

# 作者信息
MAINTAINER mritd &amp;lt;mritd@mritd.me&amp;gt;

# 获取参数
ARG SPRING_PROFILE_ACTIVE
ARG PROJECT_BUILD_FINALNAME

# 设置时区,项目参数,项目名称
ENV TZ 'Asia/Shanghai'
ENV SPRING_PROFILE_ACTIVE ${SPRING_PROFILE_ACTIVE}
ENV PROJECT_BUILD_FINALNAME ${PROJECT_BUILD_FINALNAME}

# 运行命令设置和安装 搭建项目所需要环境
RUN apk upgrade --update \
    &amp;amp;&amp;amp; apk add tzdata bash \
    &amp;amp;&amp;amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;amp;&amp;amp; echo &quot;Asia/Shanghai&quot; &amp;gt; /etc/timezone \
    &amp;amp;&amp;amp; rm -rf /var/cache/apk/*

# copy 项目中可运行的jar包到镜像中
COPY target/${PROJECT_BUILD_FINALNAME}.jar /${PROJECT_BUILD_FINALNAME}.jar

# 执行启动命令,项目使用spring-boot框架搭建,所以直接使用此命令就好
CMD [&quot;bash&quot;,&quot;-c&quot;,&quot;java -jar /${PROJECT_BUILD_FINALNAME}.jar --spring.profiles.active=${SPRING_PROFILE_ACTIVE}&quot;]

# 更复杂的Dockerfile待更新
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;三build-dcokerfile&quot;&gt;(三)build Dcokerfile&lt;/h3&gt;
&lt;p&gt;写完Dockerfile后,使用docker build 命令build自己的镜像&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker build /path/to/a/Dockerfile  -t testDocker:1.2 .

docker -H https://githu.com/xxx/xxx.git  build -t image_name:1.12 --build-arg &lt;span class=&quot;nv&quot;&gt;SPRING_PROFILE_ACTIVE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;dohko   &lt;span class=&quot;nv&quot;&gt;PROJECT_BUILD_FINALNAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;longdai-p2p-core longdai-core

&lt;span class=&quot;c&quot;&gt;# 为镜像指定tag&lt;/span&gt;
docker -H &lt;span class=&quot;nv&quot;&gt;$DOHKO_BUILD_HOST_19&lt;/span&gt; tag &lt;span class=&quot;nv&quot;&gt;$IMAGE_NAME&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$LATEST_IMAGE_NAME&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 将镜像push到指定仓库&lt;/span&gt;
docker -H &lt;span class=&quot;nv&quot;&gt;$DOHKO_BUILD_HOST_19&lt;/span&gt; push &lt;span class=&quot;nv&quot;&gt;$IMAGE_NAME&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 删除本地的docker镜像&lt;/span&gt;
docker -H &lt;span class=&quot;nv&quot;&gt;$DOHKO_BUILD_HOST_19&lt;/span&gt;  rmi &lt;span class=&quot;nv&quot;&gt;$IMAGE_NAME&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 指定build的文件来源地址&lt;/span&gt;
-H https://githu.com/xxx/xxx.git 
&lt;span class=&quot;c&quot;&gt;# build后的镜像名称为: image_name:1.12 &lt;/span&gt;
build -t image_name:1.12 
&lt;span class=&quot;c&quot;&gt;# build 时带入的参数&lt;/span&gt;
--build-arg &lt;span class=&quot;nv&quot;&gt;SPRING_PROFILE_ACTIVE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;dohko   &lt;span class=&quot;nv&quot;&gt;PROJECT_BUILD_FINALNAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;longdai-p2p-core
&lt;span class=&quot;c&quot;&gt;# build的文件中的目录&lt;/span&gt;
longdai-core



&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;更多详细的命令参考&lt;a href=&quot;https://docs.docker.com/engine/reference/builder/&quot;&gt;官方文档Dockerfile reference&lt;/a&gt;&lt;/p&gt;</content><author><name>liushan</name></author><summary type="html">docker学习笔记二–Dockerfile 参考自官方文档-Dockerfile部分</summary></entry><entry><title type="html">docker学习笔记(一)</title><link href="http://localhost:4000/2017/07/07/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/" rel="alternate" type="text/html" title="docker学习笔记(一)" /><published>2017-07-07T00:00:00+08:00</published><updated>2017-07-07T00:00:00+08:00</updated><id>http://localhost:4000/2017/07/07/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)</id><content type="html" xml:base="http://localhost:4000/2017/07/07/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/">&lt;h2 id=&quot;docker学习笔记一&quot;&gt;docker学习笔记(一)&lt;/h2&gt;

&lt;h3 id=&quot;安装docker&quot;&gt;安装docker&lt;/h3&gt;
&lt;p&gt;google一下,dokcer安装到本地即可.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;ubuntu,及其 参考地址 &lt;a href=&quot;https://docs.docker.com/engine/installation/&quot;&gt;官网安装地址&lt;/a&gt;,进行安装.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;macOs 需要下载安装包进行安装,或者使用 brew install docker 进行安装.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;安装完成后,允许docker info 查看安装信息,如果是生产环境使用,需要单独配置其他信息(如nfs&lt;文件存储相关信息&gt;),具体信息可访问docker官网进行配置&lt;/文件存储相关信息&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    
➜  ~ docker info
		Containers: 15
		 Running: 2
		 Paused: 0
		 Stopped: 13
		Images: 17
		Server Version: 17.03.1-ce
		Storage Driver: overlay2
		 Backing Filesystem: extfs
		 Supports d_type: &lt;span class=&quot;nb&quot;&gt;true
		 &lt;/span&gt;Native Overlay Diff: &lt;span class=&quot;nb&quot;&gt;true
		&lt;/span&gt;Logging Driver: json-file
		Cgroup Driver: cgroupfs
		Plugins:
		 Volume: &lt;span class=&quot;nb&quot;&gt;local
		 &lt;/span&gt;Network: bridge host ipvlan macvlan null overlay
		Swarm: inactive
		Runtimes: runc
		Default Runtime: runc
		Init Binary: docker-init
		containerd version: 4ab9917febca54791c5f071a9d1f404867857fcc
		runc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe
		init version: 949e6fa
		Security Options:
		 seccomp
		  Profile: default
		Kernel Version: 4.9.27-moby
		Operating System: Alpine Linux v3.5
		OSType: linux
		Architecture: x86_64
		CPUs: 2
		Total Memory: 1.952 GiB
		Name: moby
		ID: XAOC:ARKJ:IDEE:6Z57:KARG:V7GA:CQ2A:L3R3:4Y6L:VTDU:KACG:AGJ5
		Docker Root Dir: /var/lib/docker
		Debug Mode &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;client&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;false
		&lt;/span&gt;Debug Mode &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;server&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true
		 &lt;/span&gt;File Descriptors: 29
		 Goroutines: 36
		 System Time: 2017-07-07T08:41:25.128911087Z
		 EventsListeners: 1
		No Proxy: &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.local, 169.254/16

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;允许 docker version
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;➜  ~ docker version
		 Client:
		  Version:      17.03.1-ce
		  API version:  1.27
		  Go version:   go1.7.5
		  Git commit:   c6d412e
		  Built:        Tue Mar 28 00:40:02 2017
		  OS/Arch:      darwin/amd64
		 
		 Server:
		  Version:      17.03.1-ce
		  API version:  1.27 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;minimum version 1.12&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
		  Go version:   go1.7.5
		  Git commit:   c6d412e
		  Built:        Fri Mar 24 00:00:50 2017
		  OS/Arch:      linux/amd64
		  Experimental: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;		
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;运行hello-world&quot;&gt;运行hello world&lt;/h3&gt;

&lt;p&gt;docker run hello-world&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
➜  ~ docker run hello-world
Unable to find image &lt;span class=&quot;s1&quot;&gt;'hello-world:latest'&lt;/span&gt; locally
latest: Pulling from library/hello-world
b04784fba78d: Pull &lt;span class=&quot;nb&quot;&gt;complete
&lt;/span&gt;Digest: sha256:f3b3b28a45160805bb16542c9531888519430e9e6d6ffc09d72261b0d26ff74f
Status: Downloaded newer image &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;hello-world:latest

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the hello-world image from the Docker Hub.
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://cloud.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/engine/userguide/

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果是linux生产关键要设置docker存储驱动,一般情况编辑 /usr/lib/systemd/system/docker.service,以下为示例:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Unit]
 &lt;span class=&quot;c&quot;&gt;# 描述&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Docker Application Container Engine
 &lt;span class=&quot;nv&quot;&gt;Documentation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://docs.docker.com
 &lt;span class=&quot;c&quot;&gt;# 先决条件&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;After&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;network.target

 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Service]
 &lt;span class=&quot;nv&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;notify
 &lt;span class=&quot;c&quot;&gt;# the default is not to use systemd for cgroups because the delegate issues still&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# exists and systemd currently does not support the cgroup feature set required&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# for containers run by docker 通过docker 启动那些containers&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;ExecStart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/bin/dockerd  -H tcp://172.16.0.22:2375 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                             -H unix:///var/run/docker.sock
                             --insecure-registry registry.gozap.com &lt;span class=&quot;se&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#仓库&lt;/span&gt;
                             --storage-driver&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;overlay2 &lt;span class=&quot;se&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;# 存储驱动&lt;/span&gt;
                             --graph&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/data/docker &lt;span class=&quot;se&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#docker 相关数据存储地址&lt;/span&gt;
                             --log-driver json-file &lt;span class=&quot;se&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#日志驱动 &lt;/span&gt;
                             --log-opt max-size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;50m &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                             --log-opt max-file&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                             --log-opt &lt;span class=&quot;nv&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;dohko22
 &lt;span class=&quot;nv&quot;&gt;ExecReload&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/bin/kill -s HUP &lt;span class=&quot;nv&quot;&gt;$MAINPID&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# Having non-zero Limit*s causes performance problems due to accounting overhead&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# in the kernel. We recommend using cgroups to do container-local accounting.&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;LimitNOFILE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;infinity
 &lt;span class=&quot;nv&quot;&gt;LimitNPROC&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;infinity
 &lt;span class=&quot;nv&quot;&gt;LimitCORE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;infinity
 &lt;span class=&quot;c&quot;&gt;# Uncomment TasksMax if your systemd version supports it.&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# Only systemd 226 and above support this version.&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;#TasksMax=infinity&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;TimeoutStartSec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0
 &lt;span class=&quot;c&quot;&gt;# set delegate yes so that systemd does not reset the cgroups of docker containers&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;Delegate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yes
 &lt;span class=&quot;c&quot;&gt;# kill only the docker process, not all processes in the cgroup&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;KillMode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;process

 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Install]
 &lt;span class=&quot;nv&quot;&gt;WantedBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;multi-user.target
	
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;For Docker CE
Linux distribution  		Supported storage drivers
Docker CE on Ubuntu			aufs, devicemapper, overlay2 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Ubuntu 14.04.4 or later, 16.04 or later&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, overlay, zfs
Docker CE on Debian			aufs, devicemapper, overlay2 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Debian Stretch&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, overlay
Docker CE on CentOS			devicemapper
Docker CE on Fedora			devicemapper, overlay2 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Fedora 26 or later, experimental&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, overlay &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;experimental&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

Supported backing filesystems
Storage driver			Supported backing filesystems
overlay, overlay2		ext4, xfs
aufs					ext4, xfs
devicemapper			direct-lvm
btrfs					btrfs
zfs						zfs

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;附录1&quot;&gt;附录1&lt;/h3&gt;
&lt;p&gt;docker 一些常用命令&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker build -t friendlyname .  &lt;span class=&quot;c&quot;&gt;# Create image using this directory's Dockerfile&lt;/span&gt;
docker run -p 4000:80 friendlyname  &lt;span class=&quot;c&quot;&gt;# Run friendlyname mapping port 4000 to 80&lt;/span&gt;
docker run -d -p 4000:80 friendlyname         &lt;span class=&quot;c&quot;&gt;# Same thing, but in detached mode&lt;/span&gt;
docker ps                                 &lt;span class=&quot;c&quot;&gt;# See a list of all running containers&lt;/span&gt;
docker stop &amp;lt;&lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt;&amp;gt;                     &lt;span class=&quot;c&quot;&gt;# Gracefully stop the specified container&lt;/span&gt;
docker ps -a           &lt;span class=&quot;c&quot;&gt;# See a list of all containers, even the ones not running&lt;/span&gt;
docker &lt;span class=&quot;nb&quot;&gt;kill&lt;/span&gt; &amp;lt;&lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt;&amp;gt;                   &lt;span class=&quot;c&quot;&gt;# Force shutdown of the specified container&lt;/span&gt;
docker rm &amp;lt;&lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt;&amp;gt;              &lt;span class=&quot;c&quot;&gt;# Remove the specified container from this machine&lt;/span&gt;
docker rm &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker ps -a -q&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# Remove all containers from this machine&lt;/span&gt;
docker images -a                               &lt;span class=&quot;c&quot;&gt;# Show all images on this machine&lt;/span&gt;
docker rmi &amp;lt;imagename&amp;gt;            &lt;span class=&quot;c&quot;&gt;# Remove the specified image from this machine&lt;/span&gt;
docker rmi &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker images -q&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;             &lt;span class=&quot;c&quot;&gt;# Remove all images from this machine&lt;/span&gt;
docker login             &lt;span class=&quot;c&quot;&gt;# Log in this CLI session using your Docker credentials&lt;/span&gt;
docker tag &amp;lt;image&amp;gt; username/repository:tag  &lt;span class=&quot;c&quot;&gt;# Tag &amp;lt;image&amp;gt; for upload to registry&lt;/span&gt;
docker push username/repository:tag            &lt;span class=&quot;c&quot;&gt;# Upload tagged image to registry&lt;/span&gt;
docker run username/repository:tag                   &lt;span class=&quot;c&quot;&gt;# Run image from a registry&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;本文参考&lt;a href=&quot;https://docs.docker.com/hackathon/&quot;&gt;docker官方文档&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>liushan</name></author><summary type="html">docker学习笔记(一)</summary></entry><entry><title type="html">github.io+jekyll搭建博客</title><link href="http://localhost:4000/2017/06/28/buildBlog-github-jekyll/" rel="alternate" type="text/html" title="github.io+jekyll搭建博客" /><published>2017-06-28T00:00:00+08:00</published><updated>2017-06-28T00:00:00+08:00</updated><id>http://localhost:4000/2017/06/28/buildBlog-github-jekyll</id><content type="html" xml:base="http://localhost:4000/2017/06/28/buildBlog-github-jekyll/">&lt;h2 id=&quot;githubiojekyll搭建静态博客&quot;&gt;gitHub.io+jekyll搭建静态博客&lt;/h2&gt;

&lt;h3 id=&quot;环境准备&quot;&gt;环境准备&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;macos10.12(Linux类似)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;rvm&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;ruby 2.3.0&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;jekyll 3.2.1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;本文基于macOs的,Linux系统类似&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;一安装rvm&quot;&gt;一.安装rvm&lt;/h3&gt;
&lt;p&gt;因为国内网络原因,rvm安装需要翻墙才能访问.至于翻墙,自行想办法了.
install rvm 参考地址:&lt;a href=&quot;https://rvm.io/rvm/install&quot;&gt;https://rvm.io/rvm/install&lt;/a&gt;进行安装
中间可能需要等待有点长时间,时间视网络情况,你懂的;
安装成功输入 rvm -v 查看&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rvm -v
rvm 1.29.2 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;latest&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; by Michal Papis, Piotr Kuczynski, Wayne E. Seguin &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;https://rvm.io/]

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;hr /&gt;
&lt;h3 id=&quot;二安装ruby&quot;&gt;二.安装ruby&lt;/h3&gt;
&lt;p&gt;如果你成功安装rvm了.安装ruby就轻松了.参考
&lt;a href=&quot;https://ruby-china.org/wiki/install_ruby_guide&quot;&gt;https://ruby-china.org/wiki/install_ruby_guide&lt;/a&gt;
,soeasy&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rvm install 2.3.0
&lt;span class=&quot;c&quot;&gt;# 设置默认使用的 ruby 版本&lt;/span&gt;
rvm use 2.3.0 --default
&lt;span class=&quot;c&quot;&gt;# 安装 bundler&lt;/span&gt;
gem install bundler

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;hr /&gt;
&lt;h3 id=&quot;三安装jekyll&quot;&gt;三.安装jekyll&lt;/h3&gt;
&lt;p&gt;克隆jekyll模板
git clone https://github.com/mzlogin/mzlogin.github.io.git 到本地目录,
进入刚刚克隆的目录&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 进入主题目录&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;mzlogin.github.io
&lt;span class=&quot;c&quot;&gt;# 安装 jekyll 等&lt;/span&gt;
bundle install
&lt;span class=&quot;c&quot;&gt;# 启动&lt;/span&gt;
jekyll -H 0.0.0.0 -P 4444

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;打开浏览器可看到,删除作者自己写的_posts中的内容,替换成自己的博客markdown文件,根据博客主题作者提示改配置和文件,替换为自己的即可;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;四推送到自己github上&quot;&gt;四.推送到自己gitHub上&lt;/h3&gt;
&lt;p&gt;首先在 Github 上创建一个自己用户名的github.io，如: 用户名.github.io，之后讲刚刚修改的主题目录下的 .git 删除 ,git init 初始化,设置 git remote set-url 指向自己的github.io,最后推送到github上完成；Github 本身也是使用 jekyll 进行生成，所以会自动识别并生成博客；最后访问 http://用户名.github.io 即可.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;参考&quot;&gt;参考&lt;/h3&gt;
&lt;p&gt;本搭建教程参考
&lt;a href=&quot;https://mritd.me/2016/10/09/jekyll-create-a-static-blog/&quot;&gt;https://mritd.me/2016/10/09/jekyll-create-a-static-blog/&lt;/a&gt;&lt;/p&gt;</content><author><name>liushan</name></author><summary type="html">gitHub.io+jekyll搭建静态博客</summary></entry></feed>