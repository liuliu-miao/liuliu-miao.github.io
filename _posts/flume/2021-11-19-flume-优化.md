---
layout: post
title: Flume 优化
categories: [Flume]
description: Flume优化读取kafka写入HDFS文件系统
keywords: Flume interceptor 优化
---

# Flume优化

## 背景和现象
- 现象 
    
    因数据堆积(job停止没有自动重启)后,flink任务将数据消费完成到kafka-topic中,flume消费堆积数据到hdfs(s3)时,数据消费过慢.

- 原因
    
    修改了kafka的压缩方式,由snappy改为了 zstd,zstd在解压时速率较慢,同时由于堆积造成flume消费kafka时,网速远没达到预期.

## 解决过程
### 升级机器配置
在原有机器上调整了以下配置后,flume机器网速依然没有提升.平均值大约在42MB/s

原机器 配置: 4C 16GB
``` conf
# source
a1.sources.r1.batchSize = 40000 # 原有值 10000
a1.sources.r1.batchDurationMillis = 500 # 原有值 1000

# sink
a1.sinks.k1.hdfs.batchSize = 5000 # 原有1000
```
升级了新机器

32C 64GB后调整了批次大小和间隔时间,依然没有对消费能力有较大提升,最终平均网速也只在50MB/s左右,没有达到预想中的提升.

### 修改自定义拦截器

通过火焰图发现了拦截效果过慢,大约占用了40-45%的效率时间.

火焰图使用参考其官网: [火焰图github官网](https://github.com/jvm-profiling-tools/async-profiler)
```bash
ps -ef |grep flume
#拿到进程id -> pid

/profiler.sh -d 30 -f pid_xxx.html pid

```
优化前火焰图:
![优化前火焰图](https://github.com/liushan150/liushan150.github.io/blob/master/images/blog/upgrade_before.png?raw=true)

通过查看自定义拦截器代码
``` java
 @Override
    public Event intercept(Event event) {
        Map<String, String> headers = event.getHeaders();
        String log = new String(event.getBody(), StandardCharsets.UTF_8);
        JSONObject.parseObject(log);
        JSONObject jsonObject = JSON.parseObject(log);
        if (jsonObject.containsKey("key")) {
            headers.put("timestamp", jsonObject.getString("timestamp"));
            headers.put("xxx", jsonObject.getString("xxx"));
            headers.put("yyy", jsonObject.getString("yyy"));
            return event;
        } else {
            return null;
        }
    }

    @Override
    public List<Event> intercept(List<Event> events) {
        List<Event> list = new ArrayList<>();
        for (Event event : events) {
            Event intercept = intercept(event);
            if(intercept != null){
                list.add(intercept);
            }
        }
        return list;
    }
```
优化后的拦截器代码:使用多多线程解析 List<Event> events,同时去除了重复的JSONObject.parseObject(log);

``` java
    @Override
    public Event intercept(Event event) {
        Map<String, String> headers = event.getHeaders();
        JSONObject jsonObject = JSON.parseObject(new String(event.getBody(), StandardCharsets.UTF_8));
        if (jsonObject.containsKey("key")) {
            headers.put("timestamp", jsonObject.getString("timestamp"));
            headers.put("pid", jsonObject.getString("pid"));
            return event;
        } else {
            return null;
        }

    }

    @Override
    public List<Event> intercept(List<Event> events) {
        List<Event> list = events.stream()
                .parallel()
                .map(event -> intercept(event))
                .filter(e -> e != null).collect(Collectors.toList());
        return list;
    }
```
- 小结:
```
这里总结以下:  events.stream().parallel() 并行执行,当events 个数多的时候效果更好.同时需要属性jdk8+的lamada表达式及内部原理.
这里涉及到后期优化kafka消费者的读取批次参数了.
这对拦截器的效率提升巨大.

```
来看一下优化拦截器后的火焰图:
![优化后火焰图](https://github.com/liushan150/liushan150.github.io/blob/master/images/blog/upgrade_after.png?raw=true)

### 修改kafka读取批次和channel大小及sink的批次大小.
在高配机器上上传修改后拦截器jar后,不修改kafka消费参数时,提升效果来到了72MB/s,但是还是没有达到预期100MB+的理想情况.
``` conf
a1.sources.r1.batchSize = 40000
a1.sources.r1.batchDurationMillis = 500
a1.sources.r1.kafka.consumer.max.poll.records = 40000 #这个和a1.sources.r1.batchSize很关键
```
kafka.consumer.max.poll.records: 消费者批次拉取数据大小
a1.sources.r1.batchSize : flume的source批次写入channel时的大小.

修改上了上述参数后,重启flume,flume消费机器网速来到120MB/s达到了理想情况.

## 优化总结
1. 在flume拦截使用多线程时,首先需要批次数据更多更有利,同时和cpu个数和频率也有关一定关系.
2. flume-source:kafka-consumer批次拉取也很关键.如果设置大小.对1也有影响.
