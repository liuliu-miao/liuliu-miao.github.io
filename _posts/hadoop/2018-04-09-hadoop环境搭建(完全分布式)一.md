---
layout: post
title: hadoop完全分布式环境搭建
categories: [Hadoop]
description: hadoop完全分布式环境搭建 
keywords: hadoop, hadoop完全分布式, hadoop环境搭建
---

## 准备工作:
- 三台或三台以上机器(本文以三台虚拟机为例)
    >
    > centOS 6.8 
    >
    > VMware Fusion 10.1(maxos的虚拟机版本),window下推荐VMware 12或14稳定版 
- 每台机器安装jdk,hadoop,并配置相应的环境变量
    > 
    > jdk 1.8
    >
    > hadoop 2.7.2 

## 安装规划
- 系统中新建个非root用户, 并且 将此用户修改用户root权限
- 所需安装文件全部存于/opt/software目录中
- 所有软件安装到  /opt/module目录下
- 修改/opt目录的拥有者  chgroup hadoop hdaoop 

## 机器设置
- 配置三台机器的ip为静态ip,并能够互相ping通,且能ping通外网
- 以下已一台机器为例
- ##### 新建用户
> 新建nginx用户并增加到nginx工作组,-g后跟组名 组和用户名都为hadoop,也可更改为其他用户名
> useradd -g hadoop hadoop  (后续文章都以hadoop用户登录系统做操作)
``` bash
1、建用户：
adduser 用户名                           //新建用户
passwd 用户名                           //给用户设置密码
2、建工作组
groupadd 组名                         //新建工作组
3、新建用户同时增加工作组
useradd -g nginx nginx               //新建nginx用户并增加到nginx工作组,-g后跟组名
注：：-g 所属组 -d 家目录 -s 所用的SHELL
4、给已有的用户增加工作组
usermod -G groupname username
```

- ##### 设置静态ip 
> vim /etc/sysconfig/network-scripts/ifcfg-eth0
 ``` bash
    DEVICE=eth0
    TYPE=Ethernet
    UUID=c4fcd4b8-9338-4489-bee5-6797d077a036
    NM_CONTROLLED=yes
    # 设置静态ip地址
    IPADDR=192.168.1.102
    # 网关
    GATEWAY=192.168.1.2
    NETMASK=255.255.255.0
    # 系统启动时启用
    ONBOOT=yes
    # 设置为静态ip
    BOOTPROTO=static
    # dns
    DNS1=114.114.114.114
    PREFIX=24
    DEFROUTE=yes
    IPV4_FAILURE_FATAL=yes
    # 禁用ipv6
    IPV6INIT=no
    NAME="System eth0"
    # mac地址 对应 /etc/udev/rules.d/70-persistent-net.rules 中的 ATTR{address}的值
    # SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:0c:29:d8:7f:e3", ATTR{type}=="1", KERNEL=="eth*", NAME="eth0"
    HWADDR=00:0c:29:d8:7f:e3
    LAST_CONNECT=1520522957
```
- ##### 修改hostname
> vim /etc/sysconfig/network
``` bash
NETWORKING=yes
HOSTNAME=hadoop102
```

- ##### 重启
> sudo reboot -h now
``` bash
sudo reboot -h now 
``` 


## 安装jdk 和 hadoop
- 下载jdk 和 hadoop压缩包存于 /opt/software目录中
- 将jdk压缩包,hadoop压缩包解到  /opt/module 
> tar -zxvf 
``` bash
# 解压命令
tar -zxvf /opt/software/jdk-8u144-linux-x64.tar.gz -C /opt/module
tar -zxvf /opt/software/hadoop-2.7.2.tar.gz -C /opt/module
 ```

- 配置JAVA_HOME和PATH ,编辑/etc/profile文件,最后一行添加如下
 > sudo vim /etc/profile
``` bash
export JAVA_HOME=/opt/module/jdk1.8.0_144
export PATH=$PATH:$JAVA_HOME/bin
export HADOOP_HOME=/opt/module/hadoop-2.7.2
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
 ```

- 检验是否安装成功
> java -version 
``` bash
java version "1.8.0_144"
Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)
``` 
> hadoop version
``` bash
Hadoop 2.7.2
Subversion Unknown -r Unknown
Compiled by root on 2017-05-22T10:49Z
Compiled with protoc 2.5.0
From source with checksum d0fda26633fa762bff87ec759ebe689c
This command was run using /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar
``` 


## 配置 hadoop
- 进入到 /opt/module/hadoop-2.7.2/etc/hadoop 目录下
- ##### 编辑hadoop-env.sh 
> vim hadoop-env.sh 配置JAVA_HOME
``` bash
export JAVA_HOME=/opt/module/jdk1.8.0_144
``` 
- ##### 编辑hdfs-site.xml
> vim hdfs-site.xml

    ```  xml
    <configuration>
            # hdfs文件系统中的文件副本数量 为3(一般情况,完全分布式都是3分以上基数份)
            <property>
                    <name>dfs.replication</name>
                    <value>3</value>
            </property>
            # 第二名称辅助节点地址和端口
            <property>
                    <name>dfs.namenode.secondary.http-address</name>
                    <value>hadoop104:50090</value>
            </property>
            # 节点检测频率,用户namenode 检测datanode是否存活 120s
            <property>
                    <name>dfs.namenode.checkpoint.period</name>
                    <value>120</value>
            </property>
            # namenode存name相关数据地址
            <property>
                    <name>dfs.namenode.name.dir</name>
                    <value>/opt/module/hadoop-2.7.2/data/tmp/dfs/name</value>
            </property>

            #多namenode的name目录,其中 name1 和name2的数据不会重复
            <property>
                    <name>dfs.namenode.name.dir</name>
                    <value>file:///${hadoop.tmp.dir}/dfs/name1,file:///${hadoop.tmp.dir}/dfs/name2</value>
            </property>
            # 指定 dfs 相关的机器地址,用户上下线新的机器
            <property>
                    <name>dfs.hosts</name>
                    <value>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts</value>
            </property>
            # 指定退役的节点
            <property>
                    <name>dfs.hosts.exclude</name>
                    <value>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude</value>
            </property>
    </configuration>

    ```

- ##### 编辑 core-site.xml
> vim core-site.xml

    ``` xml
    <configuration>
        # dfs 的名称节点
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hadoop102:9000</value>
        </property>
        # dfs 系统存取数据的目录
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/opt/module/hadoop-2.7.2/data/tmp</value>
        </property>
        <property>
            <name>fs.trash.interval</name>
            <value>1</value>
        </property>
        <property>
            <name>hadoop.http.staticuser.user</name>
            <value>hadoop</value>
        </property>
    </configuration>
    ```

- ##### 配置yarn ,编辑maperd-site.xml
> vim maperd-site.xml

    ``` xml
    <configuration>
    <!-- 指定mr运行在yarn上 -->
            <property>
                    <name>mapreduce.framework.name</name>
                    <value>yarn</value>
            </property>

            <!--配置历史服务器 -->
            <property>
                    <name>mapreduce.jobhistory.address</name>
                    <value>hadoop101:10020</value>
            </property>
            <property>
                    <name>mapreduce.jobhistory.webapp.address</name>
                    <value>hadoop101:19888</value>
            </property>
    </configuration>
    ``` 
- ##### 配置集群地址
> vim slaves
``` bash
hadoop102
hadoop103
hadoop104
```

- ##### 修改其他机器的静态ip和hostname

- ##### 分发文件 
- 将/opt/moudle/目录下所有文件分发到其他机器
    ``` bash
    # 可自定义脚本执行
    rsync -rvl /opt/moudle hadoop@hadoop102:/opt/moudle
    rsync -rvl /opt/moudle hadoop@hadoop103:/opt/moudle
    rsync -rvl /opt/moudle hadoop@hadoop104:/opt/moudle
    ```
-  将/etc/profile文件分发到其他机器
    ``` bash
    rsync -rvl /etc/profile hadoop@hadoop102:/etc
    ```

-  自定义脚本分发文件
> 新建自定义脚本文件 touch /usr/bin/xsync
``` bash
sudo chmod +x /usr/bin/xsync
vim /usr/bin/xsync
```

    ``` bash
    #!/bin/bash
    # 获取输入参数个数
    pcount=$#
    if((pcount==0));then
    echo no args;
    exit;
    fi

    # 获取文件名
    p1=$1
    fname=`basename $p1`
    echo fname=$fname

    # 获取上机目录到绝对路径

    pdir=`cd -P $(dirname $p1); pwd`

    echo pdir=$pdir

    # 获取当前用户名
    user=`whoami`

    for((host=103;host<109;host++));do
            echo --------------------hadoop$host-----------------
            rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
    done

    echo "success"
    ```
